# GuÃ­a EspecÃ­fica para 16GB RAM

## Tu ConfiguraciÃ³n
- **RAM disponible**: 16 GB
- **Objetivo**: Procesar TriviaQA con Qwen3-4B-Instruct
- **LimitaciÃ³n**: Evitar Out of Memory (OOM)

---

## âœ… ConfiguraciÃ³n Ã“ptima Implementada

El sistema ahora estÃ¡ configurado para funcionar perfectamente con 16GB RAM:

### Uso de Memoria Esperado

| Componente | Memoria |
|------------|---------|
| Modelo Qwen3-4B (8-bit) | ~4 GB |
| Batch en procesamiento | ~2 GB |
| Sistema operativo | ~2 GB |
| Margen de seguridad | ~2 GB |
| **Total mÃ¡ximo** | **~10 GB** |

Tienes **6GB de margen** de seguridad âœ…

---

## ðŸš€ EjecuciÃ³n Recomendada

### Paso 1: Prueba Inicial (1000 ejemplos)

Primero, prueba con un subconjunto pequeÃ±o para validar:

1. **Editar configuraciÃ³n:**
   ```bash
   nano src/trace_extractor.py
   # O usar tu editor preferido
   ```

2. **Cambiar lÃ­nea ~148:**
   ```python
   num_samples = 1000  # Prueba con 1000 ejemplos
   ```

3. **Ejecutar:**
   ```bash
   python src/trace_extractor.py
   ```

**Resultado esperado:**
- âœ… 2 archivos batch (~10 GB total)
- âœ… Tiempo: ~30-45 minutos
- âœ… RAM mÃ¡xima: ~10 GB

### Paso 2: Verificar Resultados

```bash
python src/inspect_traces.py
```

Esto te mostrarÃ¡:
- NÃºmero de batches creados
- TamaÃ±o de cada archivo
- EstadÃ­sticas de los traces
- Ejemplos de preguntas/respuestas

### Paso 3: Procesar Dataset Completo (Opcional)

Si la prueba funciona bien, procesar todo:

1. **Cambiar configuraciÃ³n:**
   ```python
   num_samples = None  # Procesar todo TriviaQA (~87k ejemplos)
   ```

2. **Ejecutar en background** (recomendado):
   ```bash
   # Usar screen o tmux para sesiÃ³n persistente
   screen -S extraction
   
   # Dentro de screen:
   python src/trace_extractor.py 2>&1 | tee extraction.log
   
   # Desconectar: Ctrl+A, D
   # Reconectar: screen -r extraction
   ```

**Resultado esperado:**
- âœ… ~174 archivos batch
- âœ… ~870 GB en disco
- âœ… 2-3 dÃ­as de procesamiento
- âœ… RAM constante ~10 GB

---

## ðŸ“Š Monitoreo Durante EjecuciÃ³n

### Monitorear RAM
```bash
# En otra terminal
watch -n 5 'free -h'
```

### Monitorear GPU
```bash
watch -n 5 nvidia-smi
```

### Ver Progreso
```bash
tail -f extraction.log  # Si usaste tee
```

---

## ðŸ›¡ï¸ ProtecciÃ³n Contra OOM

El sistema implementa mÃºltiples salvaguardas:

1. **Batches de 500 traces**: LÃ­mite estricto de memoria
2. **Garbage collection explÃ­cito**: Libera memoria despuÃ©s de cada batch
3. **Guardado incremental**: No acumula datos en RAM
4. **Variables locales**: Se descartan al salir de scope

### Si AÃºn AsÃ­ Hay OOM

Ajustar `BATCH_SIZE` en `src/trace_extractor.py` lÃ­nea ~127:

```python
BATCH_SIZE = 250  # Reducir a 250 traces (~2.5 GB por batch)
# o incluso
BATCH_SIZE = 100  # 100 traces (~1 GB por batch)
```

---

## ðŸ’¾ GestiÃ³n de Espacio en Disco

### Verificar Espacio Disponible

```bash
df -h .
```

### Estimaciones

| ConfiguraciÃ³n | Espacio Necesario |
|---------------|-------------------|
| 1000 ejemplos | ~10 GB |
| 5000 ejemplos | ~50 GB |
| 10000 ejemplos | ~100 GB |
| Dataset completo | ~870 GB |

### Si Tienes Espacio Limitado

Opciones:
1. Procesar en partes (ej: 10k ejemplos a la vez)
2. Comprimir batches antiguos: `gzip trivia_qa_traces_batch_*.pkl`
3. Mover batches procesados a almacenamiento externo

---

## ðŸ”„ RecuperaciÃ³n Ante Interrupciones

### Si el Proceso se Interrumpe

El sistema es robusto ante fallos:

1. **Verificar batches guardados:**
   ```bash
   ls -lh traces_data/
   ```

2. **Identificar Ãºltimo batch:**
   ```bash
   ls traces_data/ | grep batch | tail -1
   ```

3. **Continuar desde ahÃ­:**
   El script NO reescribe batches existentes, automÃ¡ticamente continÃºa

### Reiniciar Desde Cero (Si Necesario)

```bash
# Respaldar batches existentes
mv traces_data traces_data_backup

# Crear directorio limpio
mkdir traces_data

# Ejecutar de nuevo
python src/trace_extractor.py
```

---

## ðŸ“ˆ Optimizaciones Adicionales

### Si el Procesamiento es Muy Lento

1. **Reducir longitud de respuestas** (lÃ­nea ~172):
   ```python
   max_new_tokens=32  # En vez de 64
   ```

2. **Usar num_beams mÃ¡s bajo** (lÃ­nea ~61):
   ```python
   num_beams=3  # En vez de 5
   ```

### Si Necesitas MÃ¡s Velocidad (Y Tienes RAM)

Aumentar batch size (âš ï¸ solo si tienes >20GB RAM):
```python
BATCH_SIZE = 1000  # ~10 GB por batch
```

---

## ðŸ§ª Testing de Recursos

### Antes de Procesar Todo

Script de prueba rÃ¡pida:
```bash
python src/test_quick.py
```

Esto procesa solo 3 ejemplos y te muestra:
- Uso de memoria
- Tiempo por ejemplo
- Dimensiones de datos extraÃ­dos

---

## ðŸ“ Notas Importantes

### âœ… Lo Que SÃ Puedes Hacer

- Procesar datasets completos sin OOM
- Interrumpir y reanudar cuando quieras
- Procesar en mÃºltiples sesiones
- Cargar y analizar batches selectivamente

### âš ï¸ Lo Que Debes Evitar

- NO cargar todos los batches simultÃ¡neamente en memoria
- NO usar `merge_batches()` a menos que tengas >100GB RAM
- NO eliminar batches durante el procesamiento

---

## ðŸŽ¯ Flujo de Trabajo Recomendado

```
1. Prueba con 1000 ejemplos
   â†“
2. Verificar resultados con inspect_traces.py
   â†“
3. Usar batch_loader.py para explorar datos
   â†“
4. Si todo OK, procesar dataset completo
   â†“
5. Implementar dataloader para grafos
   â†“
6. Entrenar VAE batch por batch
```

---

## ðŸ†˜ Troubleshooting RÃ¡pido

| Problema | SoluciÃ³n |
|----------|----------|
| OOM durante extracciÃ³n | Reducir `BATCH_SIZE` a 250 o 100 |
| Disco lleno | Reducir `num_samples` o liberar espacio |
| Proceso muy lento | Reducir `max_new_tokens` o `num_beams` |
| GPU no se usa | Verificar CUDA con `torch.cuda.is_available()` |
| Error al cargar batch | Verificar integridad con `pickle.load()` |

---

## âœ¨ Resumen Final

Con 16GB RAM puedes:
- âœ… Procesar datasets completos
- âœ… Usar batches de 500 traces
- âœ… RAM mÃ¡xima ~10 GB (sobra margen)
- âœ… RecuperaciÃ³n automÃ¡tica ante fallos
- âœ… Procesamiento eficiente y escalable

**El sistema estÃ¡ optimizado para tus recursos. Â¡Listo para usar!** ðŸš€
