<div style="display: flex; justify-content: space-around; align-items: center; width: 100%;">
 Â <img src="https://upload.wikimedia.org/wikipedia/commons/8/84/Escudo_de_la_Pontificia_Universidad_Cat%C3%B3lica_de_Chile.svg" width="72" alt="PUC Logo">
 Â <img src="https://upload.wikimedia.org/wikipedia/commons/4/47/Logo_UTFSM.png" width="100" alt="UTFSM Logo">
</div>

-----

# Hallucination Detection in LLM's with GML

This repository contains the source code for the _Graph Machine Learning (IIC3675)_ project by the lecturer Marcelo Mendoza (PUC) and authors NicolÃ¡s Schiaffino & Gabriel Venegas (UTFSM).

# Graphical Abstract

# ðŸ“ Project Repository Structure for LLM Hallucination Detection

Here is the description of the suggested repository structure in Markdown, followed by a Tree Diagram, designed for maximum modularity and academic rigor.

-----

### Repository Structure Description

This structure is organized to support the entire research lifecycle, from data processing to final result generation, emphasizing **reproducibility** and **modular code**.

| Directory | Content | Academic Rigor Justification |
| :--- | :--- | :--- |
| **`src/`** | Modular source code (Models, Pipeline components, Utilities). The core of the project. | Fosters **modularity**, allowing for the reuse of functions and classes (e.g., `VAE.py`, `GNN_Layer.py`) for clear logic separation. |
| **`data/`** | Scripts for downloading and preprocessing data. **Never** upload large `.pt` or `.pkl` files here. | Ensures **dataset reproducibility**. Only the generation scripts (e.g., `generate_llama_traces.py`) should be included. |
| **`models/`** | Trained model weights (`.pth` files). | Critical for **immediate replicability**. Users can verify results without requiring full retraining. |
| **`notebooks/`** | Jupyter Notebooks for exploration, prototyping, and analysis. | Ideal for **Exploratory Data Analysis (EDA)**, debugging the VAE, and visualizing training metrics (*loss curves*). |
| **`experiments/`** | Final scripts for training and evaluation runs. | Separates the final **execution code** from the modular development code. |
| **`results/`** | Tables, charts, and figures for the final report. The key deliverable. | Stores raw results and figures automatically generated by the evaluation scripts. |

-----

### ðŸŒ³ Tree Diagram

```mermaid
graph TD
    A[Project_Root/]
    B1[src/] --> B1_1[src/data_processing/]
    B1_1 --> B1_1_1[trace_extractor.py]
    B1_1 --> B1_1_2[graph_builder.py]
    B1_1 --> B1_1_3[dataset.py]
    B1 --> B1_2[src/models/]
    B1_2 --> B1_2_1[vae_encoder.py]
    B1_2 --> B1_2_2[mlp_scorer.py]
    B1 --> B1_3[src/evaluation/]
    B1_3 --> B1_3_1[metrics.py]
    B1_3 --> B1_3_2[baselines.py]
    
    B2[data/]
    B3[models/]
    B4[notebooks/]
    B5[experiments/] --> B5_1[experiments/1_preprocess_data.sh]
    B5 --> B5_2[experiments/2_train_vae.py]
    B5 --> B5_3[experiments/3_evaluate_mlp.py]
    B6[results/]
    B7[README.md]
    B8[environment.yml]

    A --- B1
    A --- B2
    A --- B3
    A --- B4
    A --- B5
    A --- B6
    A --- B7
    A --- B8
```

### Corresponding File System Tree

```
Project_Root/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing/
â”‚   â”‚   â”œâ”€â”€ trace_extractor.py      # Extracts LLM hidden states/attention
â”‚   â”‚   â”œâ”€â”€ graph_builder.py        # Converts traces to attributed graphs G_l
â”‚   â”‚   â””â”€â”€ dataset.py              # Dataloader for graph sequences {G_l}
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ vae_encoder.py          # Graph VAE implementation
â”‚   â”‚   â””â”€â”€ mlp_scorer.py           # Hallucination scoring MLP over Z_l
â”‚   â””â”€â”€ evaluation/
â”‚       â”œâ”€â”€ metrics.py              # AUROC, AUPR calculation
â”‚       â””â”€â”€ baselines.py            # HaloScope, HalluShift, CHARM score functions
â”œâ”€â”€ data/                           # Scripts only (e.g., generate_llama_traces.py)
â”œâ”€â”€ models/                         # Trained model weights (.pth)
â”œâ”€â”€ notebooks/                      # EDA and prototyping notebooks
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ 1_preprocess_data.sh        # Executes data pipeline
â”‚   â”œâ”€â”€ 2_train_vae.py              # VAE training script
â”‚   â””â”€â”€ 3_evaluate_mlp.py           # Final evaluation and comparison
â”œâ”€â”€ results/                        # Final tables, charts, and figures
â”œâ”€â”€ README.md                       # Project documentation
â””â”€â”€ environment.yml                 # Dependency list
```

# ToDo

### Avance
- [x] ~~Implementar Llama-3.2-1B~~ **ACTUALIZADO: Qwen3-4B-Instruct** y generar las respuestas de las preguntas de ~~_TruthfulQA_~~ **TriviaQA**
- [x] Crear script para extraer las atenciones y embeddings de todas las capas para la respuesta generada (`trace_extractor.py`)
- [x] Procesar todas las respuestas con el script para recuperar atenciones y embeddings
- [x] Generar el dataset con cada fila como `[id_pregunta, respuesta, atenciones_capa_k, activaciones_capa_k, ..., atenciones_capa_N, activaciones_capa_N]`
- [ ] Implementar un proceso de carga de cada fila de dataset para generar el Grafo (`dataloader`)
- [ ] Implementar VAE para grafos

### Entrega Final
- [ ] Entrenar el VAE de forma no supervisada sobre el dataset mixto
- [ ] Implementar scripts de scoring de alucinaciones (MLP) sobre la secuencia de z_l
- [ ] Implementar HaloScope & HalluShift para comparaciÃ³n
- [ ] Ejecutar evaluaciÃ³n en dataset de test y generar grÃ¡ficos comparativos

### Propuesta 
- [x] Graphical abstract.
- [x] Problema que se aborda en el proyecto.
- [x] TÃ©cnicas a utilizar.
- [x] Datos con los que se va a trabajar.
- [x] Elementos Diferenciadores
- [x] Plan de actividades, Entregables al avance y a la entrega final.
- [x] Video de 3 minutos.

---

## ðŸš€ Ãšltimas Actualizaciones

### ImplementaciÃ³n Fase de Avance (Actualizado)

**Modelo**: `Qwen/Qwen3-4B-Instruct-2507` (reemplaza Llama-3.2-1B)  
**Dataset**: `TriviaQA` (mandarjoshi/trivia_qa, rc.nocontext) (reemplaza TruthfulQA)

#### Archivos Implementados:

1. **`src/trace_extractor.py`** - Extractor principal de trazas
   - Carga el modelo Qwen3-4B-Instruct con cuantizaciÃ³n 8-bit
   - Procesa preguntas de TriviaQA
   - Extrae **hidden states** y **attention matrices** de todas las capas
   - Guarda datos en `./traces_data/trivia_qa_traces_*.pkl`

2. **`src/inspect_traces.py`** - Script de inspecciÃ³n de datos
   - Carga y analiza los traces guardados
   - Muestra estadÃ­sticas del dataset
   - Visualiza ejemplos y dimensiones

3. **DocumentaciÃ³n**:
   - `src/README_trace_extractor.md` - GuÃ­a detallada del extractor
   - `CAMBIOS_IMPLEMENTADOS.md` - Resumen de cambios realizados

#### Uso RÃ¡pido:

```bash
# Extraer trazas (por defecto 100 ejemplos)
python src/trace_extractor.py

# Inspeccionar datos extraÃ­dos
python src/inspect_traces.py
```

#### Estructura de Datos ExtraÃ­dos:

Cada trace contiene:
- `hidden_states`: `[num_layers][num_tokens][batch, seq_len, hidden_dim]`
- `attentions`: `[num_layers][num_tokens][batch, num_heads, seq_len, seq_len]`
- Metadata: pregunta, respuesta, tokens, ground truth answers

Ver `src/README_trace_extractor.md` para mÃ¡s detalles.