<div style="display: flex; justify-content: space-around; align-items: center; width: 100%;">
 Â <img src="https://upload.wikimedia.org/wikipedia/commons/8/84/Escudo_de_la_Pontificia_Universidad_Cat%C3%B3lica_de_Chile.svg" width="72" alt="PUC Logo">
 Â <img src="https://upload.wikimedia.org/wikipedia/commons/4/47/Logo_UTFSM.png" width="100" alt="UTFSM Logo">
</div>

-----

# Hallucination Detection in LLM's with GML

This repository contains the source code for the _Graph Machine Learning (IIC3675)_ project by the lecturer Marcelo Mendoza (PUC) and authors NicolÃ¡s Schiaffino & Gabriel Venegas (UTFSM).

# Graphical Abstract

# ðŸ“ Project Repository Structure for LLM Hallucination Detection

Here is the description of the suggested repository structure in Markdown, followed by a Tree Diagram, designed for maximum modularity and academic rigor.

-----

### Repository Structure Description

This structure is organized to support the entire research lifecycle, from data processing to final result generation, emphasizing **reproducibility** and **modular code**.

| Directory | Content | Academic Rigor Justification |
| :--- | :--- | :--- |
| **`src/`** | Modular source code (Models, Pipeline components, Utilities). The core of the project. | Fosters **modularity**, allowing for the reuse of functions and classes (e.g., `VAE.py`, `GNN_Layer.py`) for clear logic separation. |
| **`data/`** | Scripts for downloading and preprocessing data. **Never** upload large `.pt` or `.pkl` files here. | Ensures **dataset reproducibility**. Only the generation scripts (e.g., `generate_llama_traces.py`) should be included. |
| **`models/`** | Trained model weights (`.pth` files). | Critical for **immediate replicability**. Users can verify results without requiring full retraining. |
| **`notebooks/`** | Jupyter Notebooks for exploration, prototyping, and analysis. | Ideal for **Exploratory Data Analysis (EDA)**, debugging the VAE, and visualizing training metrics (*loss curves*). |
| **`experiments/`** | Final scripts for training and evaluation runs. | Separates the final **execution code** from the modular development code. |
| **`results/`** | Tables, charts, and figures for the final report. The key deliverable. | Stores raw results and figures automatically generated by the evaluation scripts. |

-----

### ðŸŒ³ Tree Diagram

```mermaid
graph TD
    A[Project_Root/]
    B1[src/] --> B1_1[src/data_processing/]
    B1_1 --> B1_1_1[trace_extractor.py]
    B1_1 --> B1_1_2[graph_builder.py]
    B1_1 --> B1_1_3[dataset.py]
    B1 --> B1_2[src/models/]
    B1_2 --> B1_2_1[vae_encoder.py]
    B1_2 --> B1_2_2[mlp_scorer.py]
    B1 --> B1_3[src/evaluation/]
    B1_3 --> B1_3_1[metrics.py]
    B1_3 --> B1_3_2[baselines.py]
    
    B2[data/]
    B3[models/]
    B4[notebooks/]
    B5[experiments/] --> B5_1[experiments/1_preprocess_data.sh]
    B5 --> B5_2[experiments/2_train_vae.py]
    B5 --> B5_3[experiments/3_evaluate_mlp.py]
    B6[results/]
    B7[README.md]
    B8[environment.yml]

    A --- B1
    A --- B2
    A --- B3
    A --- B4
    A --- B5
    A --- B6
    A --- B7
    A --- B8
```

### Corresponding File System Tree

```
Project_Root/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing/
â”‚   â”‚   â”œâ”€â”€ trace_extractor.py      # Extracts LLM hidden states/attention
â”‚   â”‚   â”œâ”€â”€ graph_builder.py        # Converts traces to attributed graphs G_l
â”‚   â”‚   â””â”€â”€ dataset.py              # Dataloader for graph sequences {G_l}
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ vae_encoder.py          # Graph VAE implementation
â”‚   â”‚   â””â”€â”€ mlp_scorer.py           # Hallucination scoring MLP over Z_l
â”‚   â””â”€â”€ evaluation/
â”‚       â”œâ”€â”€ metrics.py              # AUROC, AUPR calculation
â”‚       â””â”€â”€ baselines.py            # HaloScope, HalluShift, CHARM score functions
â”œâ”€â”€ data/                           # Scripts only (e.g., generate_llama_traces.py)
â”œâ”€â”€ models/                         # Trained model weights (.pth)
â”œâ”€â”€ notebooks/                      # EDA and prototyping notebooks
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ 1_preprocess_data.sh        # Executes data pipeline
â”‚   â”œâ”€â”€ 2_train_vae.py              # VAE training script
â”‚   â””â”€â”€ 3_evaluate_mlp.py           # Final evaluation and comparison
â”œâ”€â”€ results/                        # Final tables, charts, and figures
â”œâ”€â”€ README.md                       # Project documentation
â””â”€â”€ environment.yml                 # Dependency list
```

# ToDo

### Avance
- [ ] Implementar Llama-3.2-1B y generar las respuestas de las preguntas de _TruthfulQA_
- [ ] Crear script para extraer las atenciones y embeddings de todas las capas para la respuesta generada.
- [ ] Procesar todas las respuestas con el script para recuperar atenciones y embeddings.
- [ ] Generar el dataset con cada fila como `[id_pregunta, respuesta, atenciones_capa_k, activaciones_capa_k, ..., atenciones_capa_N, activaciones_capa_N]`
- [ ] Implementar un proceso de carga de cada fila de dataset para generar el Grafo.
- [ ] Implementar VAE.

### Entrega Final

### Propuesta 
- [x] Graphical abstract.
- [x] Problema que se aborda en el proyecto.
- [x] TÃ©cnicas a utilizar.
- [x] Datos con los que se va a trabajar.
- [x] Elementos Diferenciadores
- [x] Plan de actividades, Entregables al avance y a la entrega final.
- [x] Video de 3 minutos.