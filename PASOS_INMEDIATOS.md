# ðŸŽ¯ PASOS A SEGUIR AHORA (ACTUALIZADO)

## SituaciÃ³n Actual - PROBLEMA IDENTIFICADO âœ“

Has encontrado el error **"index out of range in self"** causado por un **mismatch entre hidden_states y attentions**.

**DiagnÃ³stico:**
```
x.shape: torch.Size([1, 4096])        # Solo 1 token
edge_index.shape: torch.Size([2, 30])  # Pero hay 30 arcos
```

**Causa:** Las atenciones tienen dimensiones mayores que el nÃºmero real de tokens.

## âœ… SOLUCIÃ“N APLICADA

Ya se corrigiÃ³ el `dataloader.py` para:
- âœ“ Recortar attentions al tamaÃ±o de hidden_states
- âœ“ Validar Ã­ndices antes de crear edge_index
- âœ“ Filtrar Ã­ndices fuera de rango

## ðŸš€ AcciÃ³n Inmediata (2 minutos)

### PASO 1: Validar Tus Datos

```bash
python src/validate_traces.py --data-pattern "traces_data/*.pkl"
```

**Esto te dirÃ¡:**
- Si hay mismatches crÃ­ticos en tus datos
- CuÃ¡ntos traces tienen el problema
- QuÃ© hacer al respecto

### PASO 2A: Si la ValidaciÃ³n Dice "TODOS VÃLIDOS"

```bash
# Ejecutar quick test
python src/quick_test.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv

# Si pasa, entrenar:
python src/baseline.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv \
    --batch-size 16 \
    --epochs 50
```

### PASO 2B: Si Hay Problemas CrÃ­ticos

El dataloader YA los maneja automÃ¡ticamente, pero si quieres limpiar los datos permanentemente:

```python
# Crear archivo clean_traces.py
import pickle
import glob
import numpy as np

def fix_traces(pattern):
    files = glob.glob(pattern)
    for file_path in files:
        with open(file_path, 'rb') as f:
            traces = pickle.load(f)
        
        for trace in traces:
            for layer_idx in range(len(trace['hidden_states'])):
                hs = trace['hidden_states'][layer_idx]
                attn = trace['attentions'][layer_idx]
                
                seq_len = hs.shape[0]
                if attn.shape[1] > seq_len or attn.shape[2] > seq_len:
                    trace['attentions'][layer_idx] = attn[:, :seq_len, :seq_len]
        
        output = file_path.replace('.pkl', '_fixed.pkl')
        with open(output, 'wb') as f:
            pickle.dump(traces, f)
        print(f"Fixed: {output}")

fix_traces("traces_data/*.pkl")
```

Luego entrenar con `*_fixed.pkl`.

#### OpciÃ³n A: Funciona en CPU pero no en GPU
**SoluciÃ³n: Usar CPU**
```bash
python src/baseline.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv \
    --force-cpu \
    --batch-size 8 \
    --epochs 50 \
    --run-lstm \
    --run-gnn-det \
    --run-gvae
```

Esto serÃ¡ mÃ¡s lento (~3-5x) pero funcionarÃ¡ sin problemas.

#### OpciÃ³n B: Hay NaN/Inf en los datos
**SoluciÃ³n: Normalizar datos**

1. Ver el script de normalizaciÃ³n en `SOLUCION_CUBLAS_ERROR.md` (SecciÃ³n "SoluciÃ³n 5")
2. Ejecutarlo sobre tus datos
3. Entrenar con datos normalizados

#### OpciÃ³n C: Valores extremos pero no NaN
**SoluciÃ³n: El cÃ³digo ya los maneja**

DeberÃ­a funcionar. Si no, reducir batch:
```bash
python src/baseline.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv \
    --batch-size 4 \
    --epochs 50
```

## ðŸš€ SoluciÃ³n RÃ¡pida sin DiagnÃ³stico

Si solo quieres que funcione YA:

```bash
# OPCIÃ“N 1: Entrenar solo LSTM (funciona seguro)
python src/baseline.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv \
    --run-lstm \
    --run-gnn-det=False \
    --run-gvae=False \
    --batch-size 16 \
    --epochs 50

# OPCIÃ“N 2: Todo en CPU (mÃ¡s lento pero funcional)
python src/baseline.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv \
    --force-cpu \
    --batch-size 8 \
    --epochs 50
```

## ðŸ”§ Soluciones Alternativas

### Alternativa 1: Actualizar PyTorch

A veces el error se debe a versiones incompatibles:

```bash
# Para CUDA 11.8
pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Para CUDA 12.1
pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Verificar versiÃ³n instalada
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.version.cuda}')"
```

### Alternativa 2: Reducir Complejidad del Modelo

```bash
python src/baseline.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv \
    --gnn-hidden 64 \      # Reducido de 128
    --lstm-hidden 128 \    # Reducido de 256
    --batch-size 8 \
    --epochs 50
```

### Alternativa 3: Cambiar Arquitectura GNN

Editar `baseline.py` para usar GCNConv en lugar de GINEConv:

```python
# En la clase GNNDetLSTM, cambiar:
from torch_geometric.nn import GCNConv  # En lugar de GINEConv

self.conv1 = GCNConv(hidden_dim, gnn_hidden)
self.conv2 = GCNConv(gnn_hidden, gnn_hidden)

# En forward(), NO pasar edge_attr:
x = F.relu(self.conv1(x, edge_index))  # Sin edge_attr
x = F.dropout(x, p=0.2, training=self.training)
x = self.conv2(x, edge_index)  # Sin edge_attr
```

GCNConv no usa edge_attr, lo que evita el error CUBLAS en esa parte.

## ðŸ“Š ComparaciÃ³n de Soluciones

| SoluciÃ³n | Tiempo | Dificultad | Probabilidad de Ã‰xito |
|----------|--------|------------|----------------------|
| Usar CPU | Inmediato | â­ Muy FÃ¡cil | 99% |
| Reducir batch | Inmediato | â­ Muy FÃ¡cil | 70% |
| Actualizar PyTorch | 5-10 min | â­â­ FÃ¡cil | 60% |
| Normalizar datos | 10-20 min | â­â­â­ Media | 90% |
| Cambiar a GCNConv | 15-30 min | â­â­â­ Media | 95% |
| Solo LSTM | Inmediato | â­ Muy FÃ¡cil | 100% |

## â±ï¸ Mi RecomendaciÃ³n

**Para obtener resultados HOY:**

1. **Ejecutar diagnÃ³stico** (2 min):
   ```bash
   python src/diagnose_cuda_error.py \
       --data-pattern "traces_data/*.pkl" \
       --scores-file ground_truth_scores.csv
   ```

2. **Si dice "funciona en CPU"**, usar CPU (inmediato):
   ```bash
   python src/baseline.py \
       --data-pattern "traces_data/*.pkl" \
       --scores-file ground_truth_scores.csv \
       --force-cpu \
       --batch-size 8 \
       --epochs 50
   ```

3. **Mientras entrena en CPU**, preparar normalizaciÃ³n de datos para futuro entrenamiento en GPU

**Para mejor rendimiento a LARGO PLAZO:**

1. Normalizar los datos (script en `SOLUCION_CUBLAS_ERROR.md`)
2. Entrenar con datos normalizados en GPU
3. O cambiar a GCNConv si la normalizaciÃ³n no funciona

## ðŸŽ¯ Comando Final Recomendado

```bash
# EJECUTAR ESTO PRIMERO (diagnÃ³stico)
python src/diagnose_cuda_error.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv

# LUEGO, BASADO EN EL RESULTADO:

# Si funciona en CPU pero no GPU â†’ Usar esto:
python src/baseline.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv \
    --force-cpu \
    --batch-size 8 \
    --epochs 50 \
    --score-threshold 0.5

# Si hay problemas en los datos â†’ Normalizar primero, luego entrenar

# Si funciona en ambos â†’ Usar GPU:
python src/baseline.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv \
    --batch-size 16 \
    --epochs 50 \
    --score-threshold 0.5
```

## ðŸ“ž Si Nada Funciona

1. **Capturar el output completo del diagnÃ³stico**
2. **Ejecutar con debug:**
   ```bash
   python src/baseline.py ... --run-gnn-det 2>&1 | tee error_log.txt
   ```
3. **Revisar** `SOLUCION_CUBLAS_ERROR.md` para soluciones avanzadas
4. **Contactar** con el log completo

## âœ… PrÃ³ximos Pasos DespuÃ©s de Resolver

Una vez que el entrenamiento funcione:

1. âœ“ Monitorear mÃ©tricas AUROC
2. âœ“ Experimentar con diferentes `--score-threshold`
3. âœ“ Comparar resultados de los 3 modelos
4. âœ“ Guardar los mejores modelos

---
**ACCIÃ“N INMEDIATA:** Ejecutar `python src/diagnose_cuda_error.py ...`
**BACKUP PLAN:** Usar `--force-cpu`
**TIEMPO ESTIMADO:** 5 minutos para tener entrenamiento corriendo
