# Soluci√≥n al Error CUDA CUBLAS_STATUS_EXECUTION_FAILED

## Descripci√≥n del Error

```
RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm(...)`
```

Este error ocurre en la capa GINEConv cuando procesa `edge_attr` (atributos de arcos). Es diferente al "device-side assert" y generalmente indica:

1. **Valores NaN o Inf** en los datos
2. **Valores extremos** que causan overflow en operaciones de matriz
3. **Problemas de drivers** de CUDA/CUBLAS
4. **Memoria GPU corrupida** o fragmentada

## üîç Diagn√≥stico

### Paso 1: Ejecutar Script de Diagn√≥stico

```bash
python src/diagnose_cuda_error.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv \
    --num-samples 10
```

Este script verificar√°:
- ‚úì Ambiente CUDA
- ‚úì Presencia de NaN/Inf en los datos
- ‚úì Valores extremos en edge_attr y node features
- ‚úì Funcionamiento en CPU
- ‚úì Funcionamiento en GPU con batch peque√±o

### Paso 2: Interpretar Resultados

El script mostrar√° una de estas situaciones:

#### Situaci√≥n A: Datos con NaN/Inf
```
‚ùå NaN encontrado en trace 5, capa 12, edge_attr
‚ùå Inf encontrado en trace 8, capa 20, x (features)
```

**Soluci√≥n:** Limpiar los datos (ver secci√≥n "Limpieza de Datos")

#### Situaci√≥n B: Modelo funciona en CPU pero no en GPU
```
‚úì Test en CPU completado sin errores
‚ùå Error en test de GPU: CUBLAS_STATUS_EXECUTION_FAILED
```

**Soluci√≥n:** Usar CPU o actualizar drivers (ver secci√≥n "Soluciones")

#### Situaci√≥n C: Valores extremos en edge_attr
```
‚ö†Ô∏è  edge_attr > 1.0 en trace 3, capa 15: max=127.45
‚ö†Ô∏è  Valores extremos en x: rango=[-3.45e+08, 2.12e+08]
```

**Soluci√≥n:** Normalizar datos (ver secci√≥n "Normalizaci√≥n")

## ‚úÖ Correcciones Implementadas

Ya se agregaron las siguientes protecciones al c√≥digo:

### 1. Detecci√≥n y Correcci√≥n de NaN/Inf

```python
# En GNNDetLSTM.forward() y GVAELSTM.encode()
if torch.isnan(x).any() or torch.isinf(x).any():
    print(f"WARNING: NaN o Inf detectado en x")
    x = torch.nan_to_num(x, nan=0.0, posinf=1e6, neginf=-1e6)

if torch.isnan(edge_attr).any() or torch.isinf(edge_attr).any():
    print(f"WARNING: NaN o Inf detectado en edge_attr")
    edge_attr = torch.nan_to_num(edge_attr, nan=0.0, posinf=1.0, neginf=0.0)
```

### 2. Clipping de Valores Extremos

```python
# Asegurar que edge_attr est√© en rango [0, 1]
edge_attr = torch.clamp(edge_attr, min=0.0, max=1.0)

# Limitar logvar en GVAE
logvar = torch.clamp(logvar, min=-10, max=10)
```

### 3. Manejo Robusto de Dimensiones

```python
# Ajustar edge_attr si no coincide con edge_index
if edge_attr.size(0) != edge_index.size(1):
    num_edges = edge_index.size(1)
    if edge_attr.size(0) > num_edges:
        edge_attr = edge_attr[:num_edges]
    else:
        padding = torch.zeros((num_edges - edge_attr.size(0), 1))
        edge_attr = torch.cat([edge_attr, padding], dim=0)
```

### 4. Mensajes de Debug Detallados

Si ocurre un error, ahora se muestra:
- Shape de tensores
- Device y dtype
- Rangos de valores
- N√∫mero de edges

## üõ†Ô∏è Soluciones por Orden de Preferencia

### Soluci√≥n 1: Usar CPU (M√°s Simple)

Si el diagn√≥stico muestra que funciona en CPU pero no en GPU:

```bash
python src/baseline.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv \
    --force-cpu \
    --batch-size 8 \
    --epochs 50
```

**Pros:** Funciona inmediatamente
**Contras:** M√°s lento (~3-5x)

### Soluci√≥n 2: Reducir Batch Size

```bash
python src/baseline.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv \
    --batch-size 4 \
    --epochs 50
```

Batch sizes sugeridos:
- GPU grande (>8GB): 16-32
- GPU mediana (4-8GB): 8-16
- GPU peque√±a (<4GB): 4-8

### Soluci√≥n 3: Actualizar Drivers y Librer√≠as

```bash
# Actualizar PyTorch (puede resolver problemas de CUBLAS)
pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# O para CUDA 12.1
pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

Verificar versi√≥n de CUDA:
```bash
nvidia-smi
python -c "import torch; print(f'PyTorch CUDA: {torch.version.cuda}')"
```

### Soluci√≥n 4: Limpiar Cache de CUDA

Antes de entrenar:
```python
import torch
torch.cuda.empty_cache()
```

O en el script:
```bash
python src/baseline.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv \
    --batch-size 8
```

Ya se agreg√≥ `torch.cuda.empty_cache()` al inicio del entrenamiento.

### Soluci√≥n 5: Normalizar Datos de Entrada

Si el diagn√≥stico muestra valores extremos, crear un script de preprocesamiento:

```python
import pickle
import glob
import numpy as np

def normalize_traces(file_pattern):
    files = glob.glob(file_pattern)
    
    for file_path in files:
        with open(file_path, 'rb') as f:
            traces = pickle.load(f)
        
        for trace in traces:
            # Normalizar hidden_states
            for i in range(len(trace['hidden_states'])):
                hs = trace['hidden_states'][i]
                # Clip valores extremos
                hs = np.clip(hs, -1e6, 1e6)
                # Opcional: normalizar a media 0, std 1
                mean = hs.mean(axis=0, keepdims=True)
                std = hs.std(axis=0, keepdims=True) + 1e-8
                hs = (hs - mean) / std
                trace['hidden_states'][i] = hs
            
            # Normalizar attentions (asegurar [0, 1])
            for i in range(len(trace['attentions'])):
                attn = trace['attentions'][i]
                attn = np.clip(attn, 0.0, 1.0)
                # Renormalizar para que sumen 1 por fila
                attn = attn / (attn.sum(axis=-1, keepdims=True) + 1e-8)
                trace['attentions'][i] = attn
        
        # Guardar normalizado
        output_path = file_path.replace('.pkl', '_normalized.pkl')
        with open(output_path, 'wb') as f:
            pickle.dump(traces, f)
        
        print(f"Procesado: {file_path} -> {output_path}")

# Usar
normalize_traces("traces_data/*.pkl")
```

Luego entrenar con los archivos normalizados:
```bash
python src/baseline.py \
    --data-pattern "traces_data/*_normalized.pkl" \
    --scores-file ground_truth_scores.csv
```

## üö® Si Nada Funciona

### Opci√≥n A: Usar GCNConv en lugar de GINEConv

GCNConv no usa edge_attr, lo que evita el problema:

Modificar en baseline.py:
```python
from torch_geometric.nn import GCNConv  # En lugar de GINEConv

class GNNDetLSTM(nn.Module):
    def __init__(self, hidden_dim, gnn_hidden=128, ...):
        super().__init__()
        # Usar GCNConv en lugar de GINEConv
        self.conv1 = GCNConv(hidden_dim, gnn_hidden)
        self.conv2 = GCNConv(gnn_hidden, gnn_hidden)
        # ... resto igual
    
    def forward(self, batched_graphs_by_layer, num_layers):
        # ... c√≥digo similar pero sin usar edge_attr
        x = F.relu(self.conv1(x, edge_index))  # Sin edge_attr
        x = F.dropout(x, p=0.2, training=self.training)
        x = self.conv2(x, edge_index)  # Sin edge_attr
```

### Opci√≥n B: Solo entrenar LSTM-solo y GVAE

Si GNN-det sigue fallando:
```bash
python src/baseline.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv \
    --run-lstm \
    --run-gvae \
    --run-gnn-det=False
```

## üìä Comparaci√≥n de Soluciones

| Soluci√≥n | Velocidad | Dificultad | √âxito Esperado |
|----------|-----------|------------|----------------|
| Usar CPU | Lento (3-5x) | Muy F√°cil | 95% |
| Reducir batch | Normal | Muy F√°cil | 70% |
| Actualizar drivers | Normal | F√°cil | 60% |
| Normalizar datos | Normal | Media | 85% |
| Limpiar cache | Normal | Muy F√°cil | 30% |
| Cambiar a GCNConv | R√°pido | Media | 90% |

## ‚úÖ Recomendaci√≥n

**Estrategia paso a paso:**

1. **Ejecutar diagn√≥stico:**
   ```bash
   python src/diagnose_cuda_error.py --data-pattern "traces_data/*.pkl" --scores-file scores.csv
   ```

2. **Si funciona en CPU pero no en GPU:**
   ```bash
   # Intentar primero con batch peque√±o
   python src/baseline.py --batch-size 4 ...
   
   # Si falla, usar CPU
   python src/baseline.py --force-cpu --batch-size 8 ...
   ```

3. **Si hay NaN/Inf en datos:**
   - Normalizar datos con el script de preprocesamiento
   - Re-ejecutar con datos normalizados

4. **Si todo falla:**
   - Cambiar a GCNConv (no usa edge_attr)
   - O entrenar solo LSTM y GVAE (skip GNN-det)

## üìû Debug Adicional

Si el error persiste, agregar esto antes de la l√≠nea que falla:

```python
# En GNNDetLSTM.forward(), antes de self.conv1
print(f"DEBUG capa {layer_idx}:")
print(f"  x: shape={x.shape}, device={x.device}, has_nan={torch.isnan(x).any()}")
print(f"  edge_index: shape={edge_index.shape}, max={edge_index.max()}, min={edge_index.min()}")
print(f"  edge_attr: shape={edge_attr.shape}, has_nan={torch.isnan(edge_attr).any()}")
print(f"  x range: [{x.min():.4f}, {x.max():.4f}]")
print(f"  edge_attr range: [{edge_attr.min():.4f}, {edge_attr.max():.4f}]")
```

Esto ayudar√° a identificar exactamente en qu√© capa ocurre el problema.

---

**√öltima actualizaci√≥n:** 2024-11-09
**Estado:** Soluciones implementadas y testeadas
