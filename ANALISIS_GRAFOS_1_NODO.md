# An√°lisis: Grafos de 1 Nodo vs Atenci√≥n al Prompt

## ü§î Tu Pregunta

> "Me parece curioso que algunos grafos solo tengan un token ya que tambi√©n quiero modelar su atenci√≥n con respecto al prompt que, evidentemente, no tendr√° un solo token. ¬øEs esto manejado por el dataloader?"

**Respuesta corta:** Tienes raz√≥n en preocuparte. Si encuentras grafos de 1 nodo, es una se√±al de alerta.

## üîç Qu√© Deber√≠a Estar Pasando

Seg√∫n el `trace_extractor.py`, los traces SE EXTRAEN con **prompt + respuesta completa**:

```python
# De trace_extractor.py l√≠neas 111-154
seq_len_total = prompt_length + num_tokens_generated

# hidden_states: [seq_len_total, hidden_dim] 
# Incluye TODOS los tokens (prompt + respuesta)

# attentions: [num_heads, seq_len_total, seq_len_total]
# Matriz completa que incluye atenci√≥n prompt‚Üîrespuesta
```

Por lo tanto, **cada grafo DEBER√çA tener**:
- Nodos = prompt tokens + respuesta tokens
- Atenciones entre TODOS los nodos (prompt puede atender a respuesta y viceversa)

## ‚ùì Entonces ¬øPor Qu√© Aparecen Grafos de 1 Nodo?

Hay 3 posibles escenarios:

### Escenario 1: Bug en la Extracci√≥n ‚ùå
```python
# Si solo se guard√≥ la respuesta, no el prompt:
hidden_states = solo_respuesta  # Shape: (1, 4096) para respuesta de 1 token
attentions = matriz_completa    # Shape: (32, 512, 512) incluyendo prompt
```

**Diagn√≥stico:** Mismatch grande (1 vs 512)
**Soluci√≥n:** Re-extraer traces correctamente

### Escenario 2: Respuestas Realmente Cortas ‚úì
```python
# Algunas preguntas tienen respuestas de 1 token + prompt normal:
hidden_states = (prompt + 1_token_respuesta)  # Shape: (50, 4096)
attentions = matriz_completa                   # Shape: (32, 50, 50)
```

**Diagn√≥stico:** Dimensiones coinciden (50 vs 50)
**Soluci√≥n:** No hay problema, es normal

### Escenario 3: Padding en Extracci√≥n ‚ö†Ô∏è
```python
# Se extrajo con max_length fijo pero seq_len real var√≠a:
hidden_states = secuencia_real   # Shape: (actual_len, 4096)
attentions = matriz_paddeada     # Shape: (32, max_len, max_len)
```

**Diagn√≥stico:** attn m√°s grande que hidden_states
**Soluci√≥n:** El dataloader recorta autom√°ticamente ‚úì

## üöÄ C√≥mo Verificar Tu Caso

### Paso 1: Inspeccionar Estructura
```bash
python src/inspect_trace_structure.py \
    --data-pattern "traces_data/*.pkl" \
    --num-samples 5
```

**Esto te dir√°:**
- Cu√°ntos nodos tienen tus grafos
- Si hidden_states y attentions coinciden
- Si hay grafos sospechosos de 1 nodo

### Paso 2: Interpretar Resultados

**Caso A: Todo coincide**
```
Capa 0: hidden_states=45 tokens, attentions=45x45 ‚úì
‚úÖ TODAS LAS CAPAS tienen dimensiones consistentes!
Prompt estimado: ~35 tokens
Respuesta estimada: ~10 tokens
```
‚Üí **Perfecto!** Los grafos incluyen prompt + respuesta

**Caso B: Grafos de 1 nodo con atenciones grandes**
```
‚ö†Ô∏è Capa 0: hidden_states=1 tokens, attentions=512x512
‚ùå CR√çTICO: Solo 1 nodo pero atenciones grandes.
¬øSe guard√≥ solo la respuesta y no el prompt?
```
‚Üí **Problema!** Solo se guard√≥ la respuesta, no el prompt

**Caso C: Atenciones m√°s grandes (padding)**
```
Capa 0: hidden_states=45 tokens, attentions=512x512
‚ö†Ô∏è WARNING: Atenciones >> hidden_states. Recortando autom√°ticamente.
```
‚Üí **OK con correcci√≥n:** El dataloader recorta a 45x45

## ‚úÖ Qu√© Hace el Dataloader

El dataloader actualizado:

1. **Detecta** el n√∫mero real de nodos desde `hidden_states`
2. **Valida** que coincida con attentions
3. **Recorta** attentions si es m√°s grande
4. **Muestra warnings** si detecta situaciones sospechosas
5. **Filtra** √≠ndices fuera de rango

```python
# Si num_nodes=45 pero attn_avg es 512x512:
attn_avg = attn_avg[:num_nodes, :num_nodes]  # Recorta a 45x45

# Si encuentra nodo=1 y attn=512x512:
print("‚ö†Ô∏è CR√çTICO: Solo 1 nodo pero atenciones grandes.")
```

## üéØ Qu√© Deber√≠as Ver en los Warnings

Al cargar el dataset con el dataloader actualizado, ver√°s:

**Si todo est√° bien:**
```
Dataset secuencial creado:
  - 1000 traces
  - 32 capas por trace
```
(Sin warnings)

**Si hay problemas:**
```
‚ö†Ô∏è WARNING: Trace qid_123, capa 0: Atenciones (512x512) >> hidden_states (1 nodos)
   ‚ö†Ô∏è CR√çTICO: Solo 1 nodo pero atenciones grandes. 
   ¬øSe guard√≥ solo la respuesta y no el prompt?
```

## üîß Si Encuentras el Problema

### Soluci√≥n Temporal (Dataloader lo Maneja)
El c√≥digo actual funciona autom√°ticamente, pero **pierdes informaci√≥n** de las atenciones al prompt.

### Soluci√≥n Correcta (Re-extraer)
Si confirmas que solo se guard√≥ la respuesta:

1. **Re-ejecutar trace_extractor.py** asegurando que se guarde todo:
   ```python
   # Verificar en trace_extractor.py l√≠nea 125:
   final_state_full = final_state[0, :seq_len_total, :].cpu().numpy()
   # seq_len_total DEBE incluir prompt + respuesta
   ```

2. **Validar** con inspect_trace_structure.py

3. **Entrenar** con traces correctos

## üìä Importancia para el Modelo

**¬øPor qu√© importa incluir el prompt?**

1. **Detecci√≥n de alucinaciones:** Las atenciones del modelo hacia el contexto (prompt) son cruciales para detectar cu√°ndo el modelo "inventa" informaci√≥n no presente en el input.

2. **An√°lisis de dependencias:** Un grafo con solo la respuesta pierde informaci√≥n sobre:
   - Qu√© partes del prompt influyeron en cada token
   - Si el modelo atendi√≥ al contexto relevante
   - Patrones de atenci√≥n an√≥malos que indican alucinaci√≥n

3. **Estructura completa:** El grafo debe modelar:
   ```
   prompt_tokens ‚Üí atenci√≥n ‚Üí response_tokens
   response_tokens ‚Üí atenci√≥n ‚Üí prompt_tokens
   response_tokens ‚Üí atenci√≥n ‚Üí response_tokens
   ```

## ‚úÖ Acci√≥n Recomendada

```bash
# 1. Inspeccionar tus traces
python src/inspect_trace_structure.py --data-pattern "traces_data/*.pkl"

# 2. Si muestra warnings cr√≠ticos de "1 nodo":
#    ‚Üí Re-extraer traces con trace_extractor.py

# 3. Si solo hay warnings de padding (attn > hidden_states):
#    ‚Üí Continuar normalmente, el dataloader lo maneja

# 4. Validar que funciona
python src/quick_test.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv

# 5. Entrenar
python src/baseline.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file ground_truth_scores.csv \
    --batch-size 16 \
    --epochs 50
```

## üìù Resumen

| Situaci√≥n | Qu√© Significa | Acci√≥n |
|-----------|---------------|--------|
| Grafos 40-100 nodos | ‚úì Incluye prompt + respuesta | Perfecto, entrenar |
| Grafos 1-5 nodos con attn grandes | ‚ùå Solo respuesta, no prompt | Re-extraer traces |
| Attn > hidden_states (padding) | ‚ö†Ô∏è Extracci√≥n con padding | OK, dataloader corrige |
| Attn = hidden_states | ‚úì Consistente | Perfecto, entrenar |

---
**√öltima actualizaci√≥n:** 2024-11-09
**Conclusi√≥n:** El dataloader maneja el problema t√©cnicamente, pero **debes verificar** que tus grafos incluyan el prompt para un an√°lisis completo de alucinaciones.
