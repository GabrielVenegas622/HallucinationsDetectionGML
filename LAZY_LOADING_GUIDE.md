# GuÃ­a RÃ¡pida: Lazy Loading para Memoria Limitada

## TL;DR - Inicio RÃ¡pido

Si tienes problemas de memoria, usa esto:

```bash
# Para entrenar con memoria limitada
python src/baseline.py \
    --preprocessed-dir preprocessed_data \
    --max-cache-batches 2 \
    --epochs 50 \
    --batch-size 16
```

O entrenar modelos uno por uno:

```bash
# Solo LSTM (usa menos memoria)
python src/baseline.py \
    --preprocessed-dir preprocessed_data \
    --max-cache-batches 2 \
    --run-lstm --no-run-gnn-det --no-run-gvae \
    --epochs 50

# Solo GNN-det+LSTM
python src/baseline.py \
    --preprocessed-dir preprocessed_data \
    --max-cache-batches 2 \
    --no-run-lstm --run-gnn-det --no-run-gvae \
    --epochs 50

# Solo GVAE+LSTM
python src/baseline.py \
    --preprocessed-dir preprocessed_data \
    --max-cache-batches 2 \
    --no-run-lstm --no-run-gnn-det --run-gvae \
    --epochs 50
```

## Â¿QuÃ© es Lazy Loading?

En lugar de cargar **todos** los datos al inicio, solo cargamos lo que necesitamos en el momento.

### Antes (Carga Completa)
```
[Inicio] â†’ Cargar 100% de datos â†’ RAM llena â†’ Entrenar
                                    â†“
                                  OOM! ðŸ’¥
```

### Ahora (Lazy Loading)
```
[Inicio] â†’ Cargar solo 2% de datos â†’ RAM OK â†’ Entrenar
            â†“                          â†“
         Solo Ã­ndice              Va cargando segÃºn necesita
```

## ParÃ¡metro Clave: --max-cache-batches

Este parÃ¡metro controla cuÃ¡ntos batches mantener en memoria:

| Valor | RAM Usada | CuÃ¡ndo Usar |
|-------|-----------|-------------|
| `1` | ~2-3 GB | RAM muy limitada (< 16 GB) |
| `2` | ~4-6 GB | **Recomendado** (16-32 GB RAM) |
| `4` | ~8-12 GB | RAM abundante (> 32 GB) |
| `8` | ~16-24 GB | GPU/servidor con mucha RAM |

## Ejemplo PrÃ¡ctico

### Sistema con 16 GB RAM

```bash
# ConfiguraciÃ³n recomendada
python src/baseline.py \
    --preprocessed-dir preprocessed_data \
    --max-cache-batches 2 \     # Solo 2 batches en memoria
    --batch-size 16 \             # Batch size moderado
    --epochs 50
```

### Sistema con 8 GB RAM

```bash
# ConfiguraciÃ³n ultra-conservadora
python src/baseline.py \
    --preprocessed-dir preprocessed_data \
    --max-cache-batches 1 \     # Solo 1 batch en memoria
    --batch-size 8 \              # Batch size pequeÃ±o
    --epochs 50
```

### Sistema con 32+ GB RAM

```bash
# ConfiguraciÃ³n Ã³ptima
python src/baseline.py \
    --preprocessed-dir preprocessed_data \
    --max-cache-batches 4 \     # 4 batches en memoria
    --batch-size 32 \             # Batch size grande
    --epochs 50
```

## Entrenamiento Secuencial AutomÃ¡tico

Usa el script preparado:

```bash
./example_train_sequential.sh
```

Este script:
1. Entrena LSTM-solo
2. Libera memoria
3. Entrena GNN-det+LSTM
4. Libera memoria
5. Entrena GVAE+LSTM

## Monitoreo de Memoria

### Durante el Entrenamiento

```bash
# Terminal 1: Entrenar
python src/baseline.py --preprocessed-dir preprocessed_data --max-cache-batches 2

# Terminal 2: Ver uso de memoria (Linux)
watch -n 1 'free -h'

# Terminal 3: Ver uso de GPU (si aplica)
watch -n 1 nvidia-smi
```

### SeÃ±ales de Alerta

**âš ï¸ Cache muy pequeÃ±o (necesitas aumentarlo):**
- Entrenamiento muy lento
- Disco trabajando constantemente
- CPU idle esperando datos

**SoluciÃ³n**: Aumentar `--max-cache-batches`

**âš ï¸ Cache muy grande (necesitas reducirlo):**
- Error "Out of Memory"
- Sistema usa SWAP
- Todo el sistema lento

**SoluciÃ³n**: Reducir `--max-cache-batches`

## Flags de Control de Modelos

Para entrenar modelos especÃ­ficos:

| Flag | FunciÃ³n |
|------|---------|
| `--run-lstm` | Entrenar LSTM-solo (default: True) |
| `--no-run-lstm` | NO entrenar LSTM-solo |
| `--run-gnn-det` | Entrenar GNN-det+LSTM (default: True) |
| `--no-run-gnn-det` | NO entrenar GNN-det+LSTM |
| `--run-gvae` | Entrenar GVAE+LSTM (default: True) |
| `--no-run-gvae` | NO entrenar GVAE+LSTM |

### Ejemplos

```bash
# Solo LSTM
python src/baseline.py \
    --preprocessed-dir preprocessed_data \
    --run-lstm --no-run-gnn-det --no-run-gvae

# Solo modelos con grafos
python src/baseline.py \
    --preprocessed-dir preprocessed_data \
    --no-run-lstm --run-gnn-det --run-gvae

# Todos (comportamiento default)
python src/baseline.py \
    --preprocessed-dir preprocessed_data \
    --run-lstm --run-gnn-det --run-gvae
```

## ComparaciÃ³n de Memoria

### Dataset Ejemplo: 1000 traces

| MÃ©todo | Memoria Total | Batches en RAM | Overhead |
|--------|---------------|----------------|----------|
| **Carga Completa** | 25 GB | 100% (todos) | Alto |
| **Lazy (cache=1)** | 2.5 GB | 1% (solo 1) | MÃ­nimo |
| **Lazy (cache=2)** | 5 GB | 2% (solo 2) | MÃ­nimo |
| **Lazy (cache=4)** | 10 GB | 4% (solo 4) | Bajo |

**ReducciÃ³n de memoria: 75-90%**

## Troubleshooting RÃ¡pido

### Problema: Out of Memory

```bash
# Prueba 1: Reducir cache
--max-cache-batches 1

# Prueba 2: Reducir batch size
--batch-size 8

# Prueba 3: Entrenar modelos por separado
--run-lstm --no-run-gnn-det --no-run-gvae
```

### Problema: Entrenamiento Muy Lento

```bash
# Prueba 1: Aumentar cache (si hay RAM)
--max-cache-batches 4

# Prueba 2: Usar SSD en lugar de HDD
# (mover preprocessed_data a SSD)

# Prueba 3: Desactivar num_workers si causa problemas
# (automÃ¡tico en el cÃ³digo)
```

### Problema: Error al Cargar Batches

```bash
# Verificar que los archivos existen
ls preprocessed_data/lstm_solo/
ls preprocessed_data/gnn/

# Verificar que tienen el prefijo correcto
ls preprocessed_data/lstm_solo/preprocessed_*.pt
```

## FAQ

**P: Â¿CuÃ¡nto tarda la indexaciÃ³n inicial?**  
R: 1-5 segundos para 1000 traces. Es muy rÃ¡pido.

**P: Â¿Afecta la precisiÃ³n del modelo?**  
R: No, es exactamente el mismo entrenamiento, solo cambia cÃ³mo se cargan los datos.

**P: Â¿Funciona con num_workers > 0?**  
R: SÃ­, pero cada worker puede cachear batches adicionales.

**P: Â¿Puedo usar esto con datos raw (.pkl.gz)?**  
R: No, lazy loading solo funciona con datos preprocesados (.pt).

**P: Â¿Necesito volver a preprocesar?**  
R: No, los archivos preprocesados existentes funcionan sin cambios.

**P: Â¿Es mÃ¡s lento que cargar todo?**  
R: Ligeramente mÃ¡s lento en la primera Ã©poca, pero despuÃ©s el cache ayuda.

**P: Â¿Funciona en Windows?**  
R: SÃ­, compatible con Windows, Linux y macOS.

## PrÃ³ximos Pasos

1. **Ejecutar test** para verificar que todo funciona:
   ```bash
   python test_preprocessing_pipeline.py
   ```

2. **Preprocesar datos reales** si aÃºn no lo has hecho:
   ```bash
   python src/preprocess_for_training.py \
       --data-pattern "traces_data/*.pkl*" \
       --scores-file ground_truth_scores.csv \
       --output-dir preprocessed_data
   ```

3. **Entrenar con lazy loading**:
   ```bash
   python src/baseline.py \
       --preprocessed-dir preprocessed_data \
       --max-cache-batches 2 \
       --epochs 50
   ```

## DocumentaciÃ³n Adicional

- **MEMORY_OPTIMIZATION.md**: ExplicaciÃ³n tÃ©cnica completa
- **BASELINE_PREPROCESSING_USAGE.md**: GuÃ­a general de uso
- **example_train_sequential.sh**: Script listo para usar

## Soporte

Si encuentras problemas:
1. Verifica la secciÃ³n de Troubleshooting
2. Revisa MEMORY_OPTIMIZATION.md para detalles tÃ©cnicos
3. Prueba con --max-cache-batches 1 primero

---

**Ãšltima actualizaciÃ³n**: Noviembre 18, 2024  
**ImplementaciÃ³n**: `src/baseline.py` con lazy loading
