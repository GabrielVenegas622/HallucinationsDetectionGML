"""
VisualizaciÃ³n de Trayectorias Latentes para Casos EspecÃ­ficos.

Este script carga un modelo GraphSequenceClassifier entrenado y busca 4 casos de uso
especÃ­ficos en el dataset de validaciÃ³n para visualizar cÃ³mo evolucionan sus
representaciones latentes (Î¼) a lo largo del tiempo.

Casos de Uso:
1.  **True Positive (Alta Confianza):** Una alucinaciÃ³n que el modelo detecta con alta probabilidad.
2.  **True Positive (Baja Confianza):** Una alucinaciÃ³n que el modelo detecta con duda (cercano al umbral).
3.  **True Negative (Baja Confianza):** Un texto verÃ­dico que el modelo casi clasifica como alucinaciÃ³n.
4.  **True Negative (Alta Confianza):** Un texto verÃ­dico que el modelo clasifica correctamente con alta probabilidad.

El script realiza los siguientes pasos:
1.  Carga el modelo y los datos de validaciÃ³n.
2.  Itera sobre un subconjunto de los datos para encontrar los 4 casos de interÃ©s.
3.  Para cada caso, extrae la secuencia de vectores de media latente (Î¼) pasando los datos
    a travÃ©s del encoder del modelo.
4.  Usa PCA para reducir la dimensionalidad de todas las secuencias a 2D.
5.  Grafica las 4 trayectorias, estilizadas por caso y confianza, con marcadores
    de inicio y fin.
"""
import torch
import numpy as np
import argparse
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from tqdm import tqdm
import gc

# Asumiendo que DynGAD.py estÃ¡ en el mismo directorio o en el python path
from DynGAD import GraphSequenceClassifier, PreprocessedGNNDataset, collate_gnn_batch

# Silenciar avisos de matplotlib sobre fuentes
import logging
logging.getLogger('matplotlib.font_manager').disabled = True


def find_target_cases(model, data_loader, device, num_samples_to_check=200):
    """
    Busca en el data_loader los 4 casos de uso especÃ­ficos.
    """
    model.eval() 
    
    # Estructura para almacenar el mejor candidato encontrado para cada caso
    # (distancia_al_target, probabilidad, Ã­ndice_en_loader, datos)
    candidates = {
        'tp_clear': {'dist': float('inf'), 'prob': -1, 'idx': -1, 'data': None, 'label': -1},
        'tp_border': {'dist': float('inf'), 'prob': -1, 'idx': -1, 'data': None, 'label': -1},
        'tn_border': {'dist': float('inf'), 'prob': -1, 'idx': -1, 'data': None, 'label': -1},
        'tn_clear': {'dist': float('inf'), 'prob': -1, 'idx': -1, 'data': None, 'label': -1},
    }
    
    print(f"ðŸ” Buscando {num_samples_to_check} muestras para encontrar casos de uso...")
    with torch.no_grad():
        for i, (batched_by_layer, labels, _) in enumerate(tqdm(data_loader, total=num_samples_to_check)):
            if i >= num_samples_to_check:
                break
            
            # Procesar de a uno para mantener la correspondencia
            graph_seq, label = batched_by_layer, labels[0].item()
            
            graph_seq_gpu = [d.to(device) for d in graph_seq]
            logits, _ = model(graph_seq_gpu)
            prob = torch.sigmoid(logits).item()

            if label == 1: # AlucinaciÃ³n (True Positive)
                # TP Claro (target > 0.9)
                dist_clear = abs(prob - 0.95)
                if prob > 0.9 and dist_clear < candidates['tp_clear']['dist']:
                    candidates['tp_clear'] = {'dist': dist_clear, 'prob': prob, 'idx': i, 'data': graph_seq, 'label': label}

                # TP Dudoso (target ~0.55)
                dist_border = abs(prob - 0.55)
                if 0.45 < prob < 0.65 and dist_border < candidates['tp_border']['dist']:
                    candidates['tp_border'] = {'dist': dist_border, 'prob': prob, 'idx': i, 'data': graph_seq, 'label': label}

            else: # Verdad (True Negative)
                # TN Claro (target < 0.1)
                dist_clear = abs(prob - 0.05)
                if prob < 0.1 and dist_clear < candidates['tn_clear']['dist']:
                    candidates['tn_clear'] = {'dist': dist_clear, 'prob': prob, 'idx': i, 'data': graph_seq, 'label': label}
                
                # TN Dudoso (target ~0.45)
                dist_border = abs(prob - 0.45)
                if 0.35 < prob < 0.55 and dist_border < candidates['tn_border']['dist']:
                    candidates['tn_border'] = {'dist': dist_border, 'prob': prob, 'idx': i, 'data': graph_seq, 'label': label}

    print("\n--- Casos Encontrados ---")
    for name, c in candidates.items():
        if c['data']:
            print(f"  âœ… {name.upper()}: Muestra #{c['idx']}, Prob={c['prob']:.3f}, Label={c['label']}")
        else:
            print(f"  âŒ {name.upper()}: No se encontrÃ³ un caso ideal.")
            
    return candidates

def extract_latent_trajectories(model, target_cases, device):
    """
    Pasa los grafos seleccionados por el encoder para extraer las secuencias de Î¼.
    """
    model.eval()
    trajectories = {}
    
    print("\nðŸ”¬ Extrayendo trayectorias latentes...")
    with torch.no_grad():
        for name, case in tqdm(target_cases.items()):
            if case['data'] is None:
                continue

            mus = []
            graph_seq_gpu = [d.to(device) for d in case['data']]
            
            for layer_data in graph_seq_gpu:
                x, edge_index, edge_attr, batch = layer_data.x, layer_data.edge_index, layer_data.edge_attr, layer_data.batch
                
                # Replicando el forward del encoder
                x = model.input_proj(x)
                x_gnn = F.relu(model.bn1(model.conv1(x, edge_index, edge_attr)))
                x_gnn = model.bn2(model.conv2(x_gnn, edge_index, edge_attr))
                
                x_dense, mask = torch_geometric.utils.to_dense_batch(x_gnn, batch, max_num_nodes=200)
                adj = torch_geometric.utils.to_dense_adj(edge_index, batch, max_num_nodes=200)
                
                s = model.pool_mlp(x_dense)
                x_pooled, _, _, _ = torch_geometric.nn.dense.dense_mincut_pool(x_dense, adj, s, mask)
                
                graph_repr = x_pooled.flatten(start_dim=1)
                graph_repr = model.pre_vae_bn(graph_repr)
                mu = model.fc_mu(graph_repr)
                mus.append(mu.cpu().numpy())
            
            trajectories[name] = np.vstack(mus)
            
    return trajectories


def visualize_trajectories(trajectories, cases_info, output_path):
    """
    Aplica PCA y grafica las trayectorias 2D.
    """
    print("ðŸŽ¨ Visualizando trayectorias con PCA...")
    
    all_mus = np.vstack([traj for traj in trajectories.values()])
    
    # Ajustar PCA con todos los puntos de todas las trayectorias
    pca = PCA(n_components=2)
    pca.fit(all_mus)
    
    # Transformar cada trayectoria individualmente
    transformed_trajs = {name: pca.transform(traj) for name, traj in trajectories.items()}
    
    plt.style.use('seaborn-v0_8-whitegrid')
    fig, ax = plt.subplots(figsize=(12, 10))
    
    styles = {
        'tp_clear':  {'color': 'red', 'linestyle': '-', 'label': 'TP (Confianza Alta)', 'alpha': 1.0},
        'tp_border': {'color': 'red', 'linestyle': '--', 'label': 'TP (Borde)', 'alpha': 0.7},
        'tn_clear':  {'color': 'blue', 'linestyle': '-', 'label': 'TN (Confianza Alta)', 'alpha': 1.0},
        'tn_border': {'color': 'blue', 'linestyle': '--', 'label': 'TN (Borde)', 'alpha': 0.7},
    }

    for name, traj_2d in transformed_trajs.items():
        style = styles[name]
        ax.plot(traj_2d[:, 0], traj_2d[:, 1], color=style['color'], linestyle=style['linestyle'], alpha=style['alpha'], label=style['label'])
        
        # Marcador de Inicio
        ax.scatter(traj_2d[0, 0], traj_2d[0, 1], marker='o', color=style['color'], s=100, edgecolors='black', zorder=5)
        ax.text(traj_2d[0, 0], traj_2d[0, 1] + 0.05, 'Inicio', fontsize=9, ha='center', color=style['color'])
        
        # Marcador de Fin
        ax.scatter(traj_2d[-1, 0], traj_2d[-1, 1], marker='X', color=style['color'], s=150, edgecolors='black', zorder=5)
        ax.text(traj_2d[-1, 0], traj_2d[-1, 1] - 0.15, 'Fin', fontsize=9, ha='center', color=style['color'])

    ax.set_title('Trayectorias en Espacio Latente (PCA) de Casos EspecÃ­ficos', fontsize=16)
    ax.set_xlabel('Componente Principal 1', fontsize=12)
    ax.set_ylabel('Componente Principal 2', fontsize=12)
    ax.legend(title="Leyenda de Casos", fontsize=10)
    ax.grid(True, which='both', linestyle='--', linewidth=0.5)
    
    fig.tight_layout()
    plt.savefig(output_path, dpi=300)
    print(f"\nâœ… GrÃ¡fico guardado en: {output_path}")
    plt.close()


def main(args):
    device = torch.device('cuda' if torch.cuda.is_available() and not args.force_cpu else 'cpu')
    print(f"Dispositivo: {device}")

    # --- Carga de Datos ---
    gnn_dir = Path(args.preprocessed_dir) / 'gnn'
    all_files = sorted(list(gnn_dir.glob('preprocessed_*.pt')))
    # Usaremos una porciÃ³n para validaciÃ³n
    _ , val_files, _ = np.split(all_files, [int(0.7*len(all_files)), int(0.85*len(all_files))])

    # El dataset para buscar casos (de a uno)
    val_dataset = PreprocessedGNNDataset(gnn_dir, val_files)
    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, collate_fn=collate_gnn_batch)
    
    # Para obtener hidden_dim, necesitamos cargar al menos un dato
    temp_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, collate_fn=collate_gnn_batch)
    sample_data = next(iter(temp_loader))
    hidden_dim = sample_data[0][0].x.shape[-1]
    del temp_loader, sample_data; gc.collect()

    # --- Carga de Modelo ---
    model_path = Path(args.model_path)
    if not model_path.exists():
        raise FileNotFoundError(f"No se encontrÃ³ el modelo en {model_path}")
        
    model = GraphSequenceClassifier(hidden_dim=hidden_dim, gnn_hidden=args.gnn_hidden, latent_dim=args.latent_dim,
                                    lstm_hidden=args.lstm_hidden, num_lstm_layers=args.num_lstm_layers,
                                    num_clusters=args.num_clusters).float()
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    print("Modelo cargado exitosamente.")

    # 1. Buscar casos
    target_cases = find_target_cases(model, val_loader, device, num_samples_to_check=args.num_samples)
    
    # 2. Extraer trayectorias
    # Necesitamos importar torch_geometric dinÃ¡micamente para el forward manual
    global torch_geometric
    import torch_geometric
    trajectories = extract_latent_trajectories(model, target_cases, device)
    
    # 3. Visualizar
    if trajectories:
        visualize_trajectories(trajectories, target_cases, args.output_file)
    else:
        print("No se encontraron trayectorias para visualizar. Terminando.")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Visualizar trayectorias latentes de casos especÃ­ficos.")
    parser.add_argument('--model-path', type=str, default='dyngad_results/best_model.pt', help='Ruta al modelo entrenado (.pt)')
    parser.add_argument('--preprocessed-dir', type=str, default='preprocessed_data', help='Directorio con datos preprocesados ("gnn")')
    parser.add_argument('--output-file', type=str, default='visualizations/latent_trajectories_cases.png', help='Ruta para guardar el grÃ¡fico.')
    parser.add_argument('--num-samples', type=int, default=200, help='NÃºmero de muestras a revisar para encontrar los casos.')
    # AÃ±adir argumentos del modelo para poder instanciarlo
    parser.add_argument('--gnn-hidden', type=int, default=256)
    parser.add_argument('--latent-dim', type=int, default=128)
    parser.add_argument('--lstm-hidden', type=int, default=32)
    parser.add_argument('--num-lstm-layers', type=int, default=2)
    parser.add_argument('--num-clusters', type=int, default=32)
    parser.add_argument('--force-cpu', action='store_true')

    args = parser.parse_args()
    
    # Crear directorio de salida si no existe
    Path(args.output_file).parent.mkdir(parents=True, exist_ok=True)
    
    main(args)
