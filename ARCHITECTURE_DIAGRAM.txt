═══════════════════════════════════════════════════════════════════════════════
  ARQUITECTURA: IterableDataset con Múltiples Workers
═══════════════════════════════════════════════════════════════════════════════

┌─────────────────────────────────────────────────────────────────────────────┐
│  ARCHIVOS PREPROCESADOS (44 archivos .pt, ~200GB total)                    │
├─────────────────────────────────────────────────────────────────────────────┤
│  preprocessed_0000.pt (250 traces, ~500MB)                                  │
│  preprocessed_0001.pt (250 traces, ~500MB)                                  │
│  preprocessed_0002.pt (250 traces, ~500MB)                                  │
│  ...                                                                         │
│  preprocessed_0043.pt (250 traces, ~500MB)                                  │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                         ┌──────────┴──────────┐
                         │   SPLIT (70/15/15)  │
                         └──────────┬──────────┘
                ┌──────────────────┼──────────────────┐
                │                  │                  │
                ▼                  ▼                  ▼
        ┌───────────────┐  ┌───────────────┐  ┌───────────────┐
        │  TRAIN FILES  │  │   VAL FILES   │  │  TEST FILES   │
        │  (31 archivos)│  │  (6 archivos) │  │  (7 archivos) │
        │               │  │               │  │               │
        │  files 0-30   │  │  files 31-36  │  │  files 37-43  │
        └───────┬───────┘  └───────────────┘  └───────────────┘
                │
                │ Asignación Round-Robin
                │
    ┌───────────┴───────────────────────────────────┐
    │                                               │
    ▼                                               ▼

┌─────────────────────────────────────────────────────────────────────────────┐
│  DataLoader con num_workers=4                                               │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐      │
│  │  Worker 0   │  │  Worker 1   │  │  Worker 2   │  │  Worker 3   │      │
│  ├─────────────┤  ├─────────────┤  ├─────────────┤  ├─────────────┤      │
│  │ files:      │  │ files:      │  │ files:      │  │ files:      │      │
│  │ 0,4,8,12... │  │ 1,5,9,13... │  │ 2,6,10,14...│  │ 3,7,11,15...│      │
│  │             │  │             │  │             │  │             │      │
│  │ RAM: 500MB  │  │ RAM: 500MB  │  │ RAM: 500MB  │  │ RAM: 500MB  │      │
│  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘      │
│         │                │                │                │              │
│         └────────────────┴────────────────┴────────────────┘              │
│                                   │                                        │
│                                   ▼                                        │
│                          ┌─────────────────┐                              │
│                          │  Batch Queue    │                              │
│                          │  (async)        │                              │
│                          └────────┬────────┘                              │
└───────────────────────────────────┼────────────────────────────────────────┘
                                    │
                                    ▼
                        ┌───────────────────────┐
                        │   Training Loop       │
                        │   (Main Process)      │
                        ├───────────────────────┤
                        │  • Recibe batches     │
                        │  • Forward/Backward   │
                        │  • GPU siempre busy   │
                        └───────────────────────┘


═══════════════════════════════════════════════════════════════════════════════
  FLUJO DE UN WORKER
═══════════════════════════════════════════════════════════════════════════════

Worker 0:
    1. Recibe lista de archivos: [0, 4, 8, 12, 16, 20, 24, 28]
    
    2. Procesa archivo 0:
       ┌─────────────────────────────────────────┐
       │ torch.load("preprocessed_0000.pt")      │  ← Carga en RAM
       │   ↓                                     │
       │ for trace in batch['sequences']:       │
       │     yield trace                         │  ← Stream
       │   ↓                                     │
       │ del batch; gc.collect()                 │  ← Libera RAM
       └─────────────────────────────────────────┘
    
    3. Procesa archivo 4:
       (mismo proceso)
    
    4. ... continúa con 8, 12, 16, etc.


═══════════════════════════════════════════════════════════════════════════════
  SHUFFLING LOCAL CON BUFFER
═══════════════════════════════════════════════════════════════════════════════

Buffer Circular de 1000 traces:

    Archivo A → [trace 1, trace 2, trace 3, ...]
                        ↓
                ┌───────────────────┐
                │  Buffer (1000)    │
                │  [t1,t2,...,t1000]│
                └─────────┬─────────┘
                          ↓
                   yield random(buffer)
                   reemplazar con nuevo trace


Características:
  • No es shuffle perfecto (pero aceptable para SGD)
  • Aleatoriedad adicional: workers procesan archivos diferentes
  • Literatura: Estándar para datasets grandes (ej: TensorFlow Datasets)


═══════════════════════════════════════════════════════════════════════════════
  COMPARACIÓN: ANTES vs AHORA
═══════════════════════════════════════════════════════════════════════════════

┌────────────────────────┬──────────────────────┬──────────────────────┐
│                        │    ANTES             │    AHORA             │
├────────────────────────┼──────────────────────┼──────────────────────┤
│ Dataset Type           │ MapStyle             │ IterableDataset      │
│ num_workers            │ 0                    │ 4                    │
│ Memoria RAM            │ ~500MB               │ ~2GB                 │
│ Tiempo/Epoch (LSTM)    │ 13 min               │ ~4 min               │
│ GPU Utilization        │ 40-50%               │ 80-90%               │
│ Shuffling              │ Global perfecto      │ Local (buffer 1000)  │
│ Paralelización         │ ❌ No                │ ✅ Sí                │
│ Escalabilidad          │ ❌ Limitada          │ ✅ Excelente         │
└────────────────────────┴──────────────────────┴──────────────────────┘


═══════════════════════════════════════════════════════════════════════════════
  USO DE MEMORIA DETALLADO
═══════════════════════════════════════════════════════════════════════════════

Proceso Principal:
  • Modelo LSTM: ~500MB GPU
  • Variables de entrenamiento: ~100MB
  • Overhead Python: ~200MB

Worker 0:
  • 1 archivo batch: ~500MB RAM
  • Overhead: ~50MB
  Total: ~550MB

Worker 1, 2, 3:
  • Similar a Worker 0
  • ~550MB cada uno

TOTAL SISTEMA:
  • GPU: ~600MB
  • RAM: ~2.8GB (4 workers × 550MB + main process)
  • Disco: Lectura secuencial (eficiente)


═══════════════════════════════════════════════════════════════════════════════
  VENTAJAS CLAVE
═══════════════════════════════════════════════════════════════════════════════

✅ VELOCIDAD
   • 3-4x más rápido que num_workers=0
   • GPU siempre ocupada (no espera datos)
   • Lectura paralela de disco

✅ MEMORIA
   • Controlada: solo N archivos (N = num_workers)
   • No carga todo el dataset
   • Escalable a 1TB+

✅ FLEXIBILIDAD
   • Ajustar num_workers según RAM disponible
   • Fácil de debuggear (num_workers=0)
   • Compatible con todo el pipeline existente

✅ LITERATURA
   • Estrategia estándar para datasets grandes
   • Usado en entrenamiento de LLMs
   • Aceptado en papers científicos


═══════════════════════════════════════════════════════════════════════════════
  CONFIGURACIÓN RECOMENDADA
═══════════════════════════════════════════════════════════════════════════════

RAM Disponible:
  • 4-8 GB   → num_workers=2
  • 8-16 GB  → num_workers=4
  • 16+ GB   → num_workers=8

Disco:
  • HDD      → num_workers=2-4
  • SSD      → num_workers=4-8

GPU:
  • Siempre usar pin_memory=True (transferencia más rápida)


═══════════════════════════════════════════════════════════════════════════════
