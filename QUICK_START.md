# ğŸš€ Quick Start: Entrenamiento RÃ¡pido con IterableDataset

## âœ… Â¿QuÃ© Se CambiÃ³?

Se reescribieron las clases de dataset para usar **IterableDataset** en lugar de MapStyle, permitiendo:

- ğŸ”¥ **3-4x mÃ¡s rÃ¡pido**: De 13 min a ~4 min por epoch
- âš¡ **num_workers=4**: ParalelizaciÃ³n real de carga de datos
- ğŸ’¾ **Memoria controlada**: Solo 1 archivo por worker (~2GB total)
- ğŸ¯ **GPU ocupada**: Mejor utilizaciÃ³n (80-90% vs 40-50%)

---

## ğŸƒ Uso Inmediato

### 1. Entrenar como siempre
```bash
python src/baseline.py \
    --preprocessed-dir preprocessed_data \
    --epochs 50 \
    --batch-size 32
```

### 2. Verificar output
DeberÃ­as ver:
```
ğŸ’¾ Estrategia: IterableDataset con mÃºltiples workers
   âš¡ Soporta num_workers > 0 para paralelizaciÃ³n
...
Configurando DataLoaders:
  - num_workers: 4 (paralelizaciÃ³n real)
  - Memoria: ~4 archivos batch en memoria simultÃ¡neos
  âš¡ Cada worker procesa archivos diferentes en paralelo
```

### 3. Esperar resultados mÃ¡s rÃ¡pidos
- **Antes:** ~13 min/epoch
- **Ahora:** ~4 min/epoch

---

## ğŸ›ï¸ Ajustar num_workers (Opcional)

Si tienes **poca RAM** (< 8GB):

Edita `src/baseline.py` lÃ­nea ~1760:
```python
# Cambiar esta lÃ­nea:
num_workers = min(len(train_lstm_files), num_cpus, 4)

# A un valor fijo menor:
num_workers = 2  # Por ejemplo
```

---

## ğŸ“Š Monitoreo

### Durante entrenamiento, revisa:

**GPU:**
```bash
watch -n 1 nvidia-smi
```
DeberÃ­as ver ~80-90% GPU utilization (antes era ~40-50%)

**RAM:**
```bash
watch -n 1 free -h
```
Uso esperado: ~2-4GB (depende de num_workers)

---

## ğŸ› Si Algo Falla

### Error: "Out of Memory"
```bash
# Reducir workers
# En baseline.py lÃ­nea ~1760:
num_workers = 1
```

### Error: "Too many open files"
```bash
# Reducir workers
num_workers = 2
```

### Entrenamiento sigue lento
- Verificar que `num_workers > 0` en output
- Verificar GPU con `nvidia-smi`
- Verificar disco (SSD vs HDD)

---

## ğŸ“š MÃ¡s InformaciÃ³n

- `CAMBIOS_REALIZADOS.md` â†’ Resumen ejecutivo
- `README_ITERABLE_DATASET.md` â†’ GuÃ­a completa
- `ITERABLE_DATASET_CHANGES.md` â†’ Detalles tÃ©cnicos
- `ARCHITECTURE_DIAGRAM.txt` â†’ Diagramas visuales

---

## âœ¨ TL;DR

1. **No cambies nada en tu comando de entrenamiento**
2. **El cÃ³digo ya estÃ¡ optimizado automÃ¡ticamente**
3. **Espera 3-4x speedup**
4. **Si falla por memoria, reduce num_workers manualmente**

Â¡Eso es todo! ğŸ‰
