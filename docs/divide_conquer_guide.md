# Divide and Conquer - GuÃ­a de Uso

## ğŸ“‹ DescripciÃ³n

Script para dividir batches grandes de traces (1000 traces, ~14GB) en batches mÃ¡s pequeÃ±os (250 traces, ~3.5GB cada uno) para mejorar la gestiÃ³n de memoria.

## ğŸ¯ Casos de Uso

### Problema
Tienes batches de 1000 traces que pesan ~14GB cada uno, lo cual:
- Consume demasiada RAM al cargar
- Hace el cache LRU menos eficiente
- Dificulta el procesamiento en mÃ¡quinas con poca memoria

### SoluciÃ³n
Dividir cada batch de 1000 traces en 4 batches de 250 traces (~3.5GB cada uno)

## ğŸš€ Uso RÃ¡pido

### Dividir todos los archivos en un directorio
```bash
python divide_conquer.py \
    --input traces_data/ \
    --output traces_data_split/
```

Esto:
- Busca todos los archivos `.pkl` y `.pkl.gz` en `traces_data/`
- Divide cada uno en batches de 250 traces (default)
- Guarda los resultados en `traces_data_split/`
- Mantiene los archivos originales
- Valida que la divisiÃ³n sea correcta

### Dividir un archivo especÃ­fico
```bash
python divide_conquer.py \
    --input traces_data/llama2_chat_7B_triviaqa_batch_0000.pkl.gz \
    --output traces_data_split/
```

## âš™ï¸ Opciones Avanzadas

### Cambiar el tamaÃ±o de los batches
```bash
# Batches de 100 traces
python divide_conquer.py \
    --input traces_data/ \
    --output traces_data_split/ \
    --traces-per-batch 100

# Batches de 500 traces
python divide_conquer.py \
    --input traces_data/ \
    --output traces_data_split/ \
    --traces-per-batch 500
```

### Sin comprimir (archivos .pkl en lugar de .pkl.gz)
```bash
python divide_conquer.py \
    --input traces_data/ \
    --output traces_data_split/ \
    --no-compress
```

**Nota**: No recomendado. Los archivos sin comprimir ocupan ~3-4x mÃ¡s espacio.

### Eliminar archivos originales (Â¡CUIDADO!)
```bash
python divide_conquer.py \
    --input traces_data/ \
    --output traces_data_split/ \
    --delete-original
```

**âš ï¸ ADVERTENCIA**: 
- Solo elimina originales si la validaciÃ³n es exitosa
- PedirÃ¡ confirmaciÃ³n antes de proceder
- **Haz un backup antes de usar esta opciÃ³n**

### Modo rÃ¡pido (sin validaciÃ³n)
```bash
python divide_conquer.py \
    --input traces_data/ \
    --output traces_data_split/ \
    --no-validate
```

**Nota**: MÃ¡s rÃ¡pido pero menos seguro. Solo usar si confÃ­as en que el proceso funcionarÃ¡ bien.

## ğŸ“Š Ejemplo Completo

### Escenario
Tienes:
- `traces_data/batch_0000.pkl.gz` - 1000 traces, 14 GB
- `traces_data/batch_0001.pkl.gz` - 1000 traces, 14 GB

### Comando
```bash
python divide_conquer.py \
    --input traces_data/ \
    --output traces_data_split/ \
    --traces-per-batch 250
```

### Resultado
```
traces_data_split/
â”œâ”€â”€ batch_0000_sub0000.pkl.gz  # Traces 0-249 (~3.5 GB)
â”œâ”€â”€ batch_0000_sub0001.pkl.gz  # Traces 250-499 (~3.5 GB)
â”œâ”€â”€ batch_0000_sub0002.pkl.gz  # Traces 500-749 (~3.5 GB)
â”œâ”€â”€ batch_0000_sub0003.pkl.gz  # Traces 750-999 (~3.5 GB)
â”œâ”€â”€ batch_0001_sub0000.pkl.gz  # Traces 0-249 (~3.5 GB)
â”œâ”€â”€ batch_0001_sub0001.pkl.gz  # Traces 250-499 (~3.5 GB)
â”œâ”€â”€ batch_0001_sub0002.pkl.gz  # Traces 500-749 (~3.5 GB)
â””â”€â”€ batch_0001_sub0003.pkl.gz  # Traces 750-999 (~3.5 GB)
```

## ğŸ” Proceso Detallado

Para cada archivo de entrada, el script:

1. **Carga** el archivo completo en memoria
2. **Divide** en sub-batches del tamaÃ±o especificado
3. **Guarda** cada sub-batch con nombre secuencial
4. **Valida** que el nÃºmero total de traces coincide
5. **Libera** memoria con `gc.collect()` entre operaciones
6. **Reporta** el progreso y estadÃ­sticas

### ValidaciÃ³n
El script valida automÃ¡ticamente que:
- NÃºmero de traces original = suma de traces en sub-batches
- Todos los archivos se guardaron correctamente
- Si la validaciÃ³n falla, se aborta y se eliminan archivos parciales

## ğŸ’¡ Recomendaciones

### TamaÃ±o de Batch Ã“ptimo

| RAM Disponible | Traces/Batch Recomendado | Archivos en Cache |
|----------------|--------------------------|-------------------|
| 8-16 GB        | 100-150                  | 2                 |
| 16-32 GB       | 200-250                  | 2-3               |
| 32-64 GB       | 250-500                  | 3-5               |
| 64+ GB         | 500-1000                 | 5-10              |

### Workflow Recomendado

1. **Hacer backup** de tus archivos originales
2. **Probar con un archivo** primero:
   ```bash
   python divide_conquer.py \
       --input traces_data/batch_0000.pkl.gz \
       --output traces_data_split_test/
   ```
3. **Verificar resultado** manualmente
4. **Procesar todo** si funciona:
   ```bash
   python divide_conquer.py \
       --input traces_data/ \
       --output traces_data_split/
   ```
5. **Probar con dataloader**:
   ```bash
   # Actualizar path en tu cÃ³digo
   dataset = TraceGraphDataset("traces_data_split/*.pkl.gz")
   ```
6. **Opcional**: Eliminar originales si todo funciona

## ğŸ¯ IntegraciÃ³n con Dataloader Optimizado

DespuÃ©s de dividir los batches, el dataloader optimizado serÃ¡ aÃºn mÃ¡s eficiente:

```python
from dataloader import TraceGraphDataset

# Antes: cache de 2 archivos = 2 Ã— 14GB = 28GB RAM
dataset = TraceGraphDataset("traces_data/*.pkl.gz")

# DespuÃ©s: cache de 2 archivos = 2 Ã— 3.5GB = 7GB RAM
dataset = TraceGraphDataset("traces_data_split/*.pkl.gz")
```

**Beneficios adicionales**:
- Cache mÃ¡s eficiente (2 archivos de 3.5GB vs 14GB)
- Menor latencia al cargar archivos
- Mejor aprovechamiento de RAM
- MÃ¡s archivos pueden caber en cache

## ğŸ“ˆ EstadÃ­sticas Esperadas

### Para 1 batch de 1000 traces (14GB)

**Antes**:
```
traces_data/batch_0000.pkl.gz  14 GB
```

**DespuÃ©s** (250 traces/batch):
```
traces_data_split/batch_0000_sub0000.pkl.gz  3.5 GB
traces_data_split/batch_0000_sub0001.pkl.gz  3.5 GB
traces_data_split/batch_0000_sub0002.pkl.gz  3.5 GB
traces_data_split/batch_0000_sub0003.pkl.gz  3.5 GB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: 14 GB (mismo tamaÃ±o, 4 archivos)
```

### Tiempo Estimado

| OperaciÃ³n | Tiempo (aprox) |
|-----------|----------------|
| Cargar 14GB | 30-60 seg |
| Dividir en 4 | 10-20 seg |
| Guardar 4 archivos | 60-120 seg |
| Validar | 30-60 seg |
| **Total por archivo** | **2-4 min** |

Para 10 batches de 14GB: ~20-40 minutos

## ğŸ› Troubleshooting

### Error: Out of Memory
**Problema**: No hay suficiente RAM para cargar el archivo completo

**SoluciÃ³n**:
```bash
# Procesar archivos uno a uno en lugar de todo el directorio
for file in traces_data/*.pkl.gz; do
    python divide_conquer.py --input "$file" --output traces_data_split/
    # Esperar que termine antes de procesar el siguiente
done
```

### Error: "No se pudo guardar"
**Problema**: No hay espacio en disco

**SoluciÃ³n**: 
- Verificar espacio: `df -h`
- Liberar espacio o usar otro directorio de salida
- Considerar `--delete-original` para liberar espacio progresivamente

### Archivos .part residuales
**Problema**: Quedan archivos `.part` de ejecuciones fallidas

**SoluciÃ³n**:
```bash
# Limpiar archivos .part
rm traces_data_split/*.part
```

### ValidaciÃ³n falla
**Problema**: NÃºmero de traces no coincide

**SoluciÃ³n**:
- Verificar integridad del archivo original:
  ```python
  import pickle, gzip
  with gzip.open('archivo.pkl.gz', 'rb') as f:
      data = pickle.load(f)
      print(f"Traces: {len(data)}")
  ```
- Reportar el error con el archivo problemÃ¡tico

## ğŸ“ Argumentos Completos

```
usage: divide_conquer.py [-h] --input INPUT --output OUTPUT
                        [--traces-per-batch N] [--no-compress]
                        [--delete-original] [--no-validate]
                        [--pattern PATTERN] [--quiet]

Argumentos:
  -h, --help            Mostrar ayuda
  --input, -i INPUT     Archivo o directorio de entrada (requerido)
  --output, -o OUTPUT   Directorio de salida (requerido)
  --traces-per-batch N, -n N
                        Traces por batch (default: 250)
  --no-compress         No comprimir salida con gzip
  --delete-original     Eliminar originales (Â¡CUIDADO!)
  --no-validate         No validar divisiÃ³n
  --pattern PATTERN     PatrÃ³n de archivos (default: *.pkl*)
  --quiet, -q          Modo silencioso
```

## âœ… Checklist de Uso

Antes de ejecutar:
- [ ] Tienes backup de los datos originales
- [ ] Verificaste espacio en disco (â‰¥ tamaÃ±o original)
- [ ] Probaste con un archivo primero
- [ ] Entiendes que `--delete-original` elimina los archivos

Durante ejecuciÃ³n:
- [ ] Monitorea uso de RAM: `watch free -h`
- [ ] Monitorea espacio en disco: `watch df -h`
- [ ] Revisa logs de errores

DespuÃ©s de ejecutar:
- [ ] Verifica que el nÃºmero de archivos es correcto
- [ ] Prueba cargar archivos con dataloader
- [ ] Compara tamaÃ±os originales vs divididos
- [ ] Considera eliminar originales solo si todo funciona

## ğŸ†˜ Ayuda

Para ver ayuda completa:
```bash
python divide_conquer.py --help
```

Para reportar problemas, incluye:
- Comando ejecutado
- Output completo del script
- TamaÃ±o de archivos: `ls -lh traces_data/`
- RAM disponible: `free -h`

---

**Ãšltima actualizaciÃ³n**: 2024-11-17  
**VersiÃ³n**: 1.0
