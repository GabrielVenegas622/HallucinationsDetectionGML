# Resumen Ejecutivo: Experimentos de AblaciÃ³n

## ğŸ“Š Objetivo

Implementar una **estrategia de ablaciÃ³n cientÃ­fica** para probar la hipÃ³tesis central:

> La dinÃ¡mica estructural secuencial a travÃ©s de las capas es la seÃ±al clave para detectar alucinaciones.

## ğŸ¯ Arquitectura de la AblaciÃ³n

### Tabla Comparativa

| Modelo | Estructura de Grafo | Incertidumbre | Componentes |
|--------|---------------------|---------------|-------------|
| **LSTM-solo** | âŒ No | âŒ No | Solo secuencia temporal |
| **GNN-det+LSTM** | âœ… SÃ­ (determinista) | âŒ No | GCN + LSTM |
| **GVAE+LSTM** | âœ… SÃ­ (variacional) | âœ… SÃ­ | GVAE + LSTM |

### HipÃ³tesis a Probar

```
Si: GVAE+LSTM > GNN-det+LSTM > LSTM-solo
Entonces:
  1. Estructura del grafo aporta valor (GNN-det > LSTM)
  2. Modelado de incertidumbre aporta valor adicional (GVAE > GNN-det)
```

## ğŸ”§ ImplementaciÃ³n

### Archivo Principal
`src/baseline.py` (~1000 lÃ­neas)

### Componentes Clave

1. **Modelos** (3 clases):
   - `LSTMBaseline`: Baseline sin estructura
   - `GNNDetLSTM`: Con estructura determinista (CHARM-style)
   - `GVAELSTM`: Con estructura + variacional (propuesto)

2. **Dataset**:
   - `SequentialTraceDataset`: Organiza grafos por trace completo
   - `collate_sequential_batch`: Agrupa grafos por capa

3. **Entrenamiento**:
   - `train_lstm_baseline()`: Entrena LSTM-solo
   - `train_gnn_det_lstm()`: Entrena GNN-det+LSTM
   - `train_gvae_lstm()`: Entrena GVAE+LSTM con pÃ©rdida VAE

4. **Experimento Principal**:
   - `run_ablation_experiments()`: Ejecuta los 3 experimentos y compara

## ğŸ“ˆ Flujo de Datos

```
Traces (.pkl) â†’ SequentialTraceDataset â†’ Train/Val/Test Split
                                                â†“
                                         DataLoaders
                                                â†“
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â†“                       â†“                       â†“
                  LSTM-solo              GNN-det+LSTM             GVAE+LSTM
                        â†“                       â†“                       â†“
              Promediar nodos           GCN por capa            GVAE por capa
                        â†“                       â†“                       â†“
              LSTM secuencial           LSTM secuencial         LSTM secuencial
                        â†“                       â†“                       â†“
                  ClasificaciÃ³n            ClasificaciÃ³n           ClasificaciÃ³n
                        â†“                       â†“                       â†“
                    Score                    Score              Score + VAE Loss
```

## ğŸ® Uso RÃ¡pido

```bash
# Comando mÃ­nimo
python src/baseline.py \
    --data-pattern "traces_data/*.pkl" \
    --scores-file "ground_truth_scores.csv"

# Comando completo con ajustes
python src/baseline.py \
    --data-pattern "traces_data/*triviaqa*.pkl" \
    --scores-file "ground_truth_triviaqa.csv" \
    --epochs 50 \
    --batch-size 16 \
    --lr 0.001 \
    --gnn-hidden 128 \
    --latent-dim 64 \
    --lstm-hidden 256 \
    --output-dir ./ablation_results
```

## ğŸ“Š Salidas Esperadas

### 1. Tabla de Resultados (stdout)
```
RESULTADOS FINALES - TABLA DE ABLACIÃ“N
================================================================
Modelo                    Best Val Loss       Best Val MAE
----------------------------------------------------------------
GVAE+LSTM                      0.1654             0.2543
GNN-det+LSTM                   0.1982             0.2987
LSTM-solo                      0.2341             0.3421
----------------------------------------------------------------
```

### 2. VerificaciÃ³n de HipÃ³tesis (stdout)
```
VERIFICACIÃ“N DE HIPÃ“TESIS
================================================================
LSTM-solo:     0.2341
GNN-det+LSTM:  0.1982 (âœ“ mejor que LSTM-solo)
GVAE+LSTM:     0.1654 (âœ“ mejor que GNN-det+LSTM)

ğŸ‰ HIPÃ“TESIS CONFIRMADA:
   GVAE+LSTM > GNN-det+LSTM > LSTM-solo
   La estructura del grafo Y la incertidumbre variacional aportan valor.
```

### 3. Archivos Generados
```
ablation_results/
â”œâ”€â”€ ablation_results_20250109_143022.json  # MÃ©tricas completas
â”œâ”€â”€ best_lstm_baseline.pt                   # Modelo LSTM entrenado
â”œâ”€â”€ best_gnn_det_lstm.pt                   # Modelo GNN-det entrenado
â””â”€â”€ best_gvae_lstm.pt                      # Modelo GVAE entrenado
```

## ğŸ”¬ Detalles TÃ©cnicos

### PÃ©rdidas

**LSTM-solo y GNN-det+LSTM:**
```python
Loss = MSE(predictions, scores)
```

**GVAE+LSTM:**
```python
Task_Loss = MSE(predictions, scores)
Recon_Loss = MSE(reconstructed, original)
KL_Loss = -0.5 * Î£(1 + log(ÏƒÂ²) - Î¼Â² - ÏƒÂ²)
Total_Loss = Task_Loss + 0.1 * (Recon_Loss + kl_weight * KL_Loss)
```

### Arquitecturas Detalladas

**LSTM-solo:**
```
Input: [batch, num_layers, hidden_dim]
    â†“
BiLSTM(256 hidden, 2 layers)
    â†“
FC(512 â†’ 128 â†’ 64 â†’ 1)
    â†“
Output: [batch, 1]
```

**GNN-det+LSTM:**
```
For each layer:
    Graph â†’ GCN(hiddenâ†’128) â†’ GCN(128â†’128) â†’ GlobalMeanPool
    
Sequence of layer representations:
    â†“
BiLSTM(128 â†’ 256 hidden, 2 layers)
    â†“
FC(512 â†’ 128 â†’ 64 â†’ 1)
    â†“
Output: [batch, 1]
```

**GVAE+LSTM:**
```
For each layer:
    Graph â†’ GCN â†’ GlobalMeanPool â†’ [Î¼, log(ÏƒÂ²)]
    z = Î¼ + Ïƒ * Îµ  (reparameterization)
    reconstruction = Decoder(z)
    
Sequence of z:
    â†“
BiLSTM(64 â†’ 256 hidden, 2 layers)
    â†“
FC(512 â†’ 128 â†’ 64 â†’ 1)
    â†“
Output: [batch, 1] + VAE losses
```

## ğŸ’¡ Ventajas de Este Enfoque

### 1. **AblaciÃ³n Limpia**
Cada modelo aÃ±ade **exactamente un componente**:
- LSTM-solo â†’ GNN-det: AÃ±ade estructura
- GNN-det â†’ GVAE: AÃ±ade incertidumbre

### 2. **ComparaciÃ³n Justa**
- Mismo dataset, mismo split
- Mismo nÃºmero de capas LSTM
- Misma funciÃ³n de pÃ©rdida base (MSE)
- Mismo proceso de entrenamiento

### 3. **Interpretabilidad**
Si GVAE > GNN-det > LSTM:
- âœ… Sabemos que estructura aporta
- âœ… Sabemos que incertidumbre aporta
- âœ… Podemos cuantificar cada contribuciÃ³n

### 4. **Publicable**
Este es el formato estÃ¡ndar de ablaciÃ³n en papers de ML:
- Baseline simple
- AÃ±adir componente A
- AÃ±adir componente B
- Probar A > baseline y A+B > A

## âš™ï¸ Configuraciones Recomendadas

### Dataset PequeÃ±o (<1000 traces)
```bash
--epochs 100 \
--batch-size 8 \
--lr 0.0005 \
--dropout 0.5 \
--gnn-hidden 64 \
--lstm-hidden 128
```

### Dataset Mediano (1000-5000 traces)
```bash
--epochs 50 \
--batch-size 16 \
--lr 0.001 \
--dropout 0.3 \
--gnn-hidden 128 \
--lstm-hidden 256
```

### Dataset Grande (>5000 traces)
```bash
--epochs 30 \
--batch-size 32 \
--lr 0.001 \
--dropout 0.2 \
--gnn-hidden 256 \
--lstm-hidden 512
```

## ğŸš€ PrÃ³ximos Pasos

### 1. Ejecutar Experimentos
```bash
python src/baseline.py --data-pattern "traces_data/*.pkl" --scores-file scores.csv
```

### 2. Analizar Resultados
- Verificar si hipÃ³tesis se confirma
- Analizar curvas de aprendizaje
- Identificar overfitting/underfitting

### 3. Ajustar HiperparÃ¡metros
Si resultados no son buenos:
- Aumentar `--epochs`
- Ajustar `--lr`
- Modificar `--dropout`
- Cambiar `--kl-weight` para GVAE

### 4. Visualizar
Crear grÃ¡ficas de:
- Train/Val loss por Ã©poca
- ComparaciÃ³n de MAE
- AnÃ¡lisis de errores

### 5. Reportar
Usar tabla de ablaciÃ³n en paper/presentaciÃ³n

## ğŸ“š Archivos Relacionados

- `src/baseline.py` - Script principal
- `src/dataloader.py` - Dataset de grafos
- `src/trace_extractor.py` - ExtracciÃ³n de traces
- `src/trace_to_gt.py` - GeneraciÃ³n de ground truth
- `docs/BASELINE_ABLATION_GUIDE.md` - GuÃ­a completa

## âœ… Checklist de ValidaciÃ³n

Antes de ejecutar, verificar:

- [ ] Traces extraÃ­dos en `traces_data/`
- [ ] Ground truth generado (`ground_truth_scores.csv`)
- [ ] GPU disponible (recomendado)
- [ ] Suficiente espacio en disco (~1-2 GB para modelos)
- [ ] PyTorch y PyTorch Geometric instalados
- [ ] Dataset tiene al menos 100 traces para split razonable

## ğŸ“ InterpretaciÃ³n para Paper

### Si GVAE > GNN-det > LSTM:

> "Nuestros experimentos de ablaciÃ³n (Tabla X) demuestran que la incorporaciÃ³n 
> de estructura de grafo mejora significativamente el baseline (GNN-det vs LSTM: 
> X% de mejora en MAE). AdemÃ¡s, el modelado variacional de la incertidumbre 
> aporta una mejora adicional (GVAE vs GNN-det: Y% de mejora), confirmando 
> nuestra hipÃ³tesis de que tanto la estructura como la incertidumbre son seÃ±ales 
> clave para la detecciÃ³n de alucinaciones."

### Si GNN-det > LSTM pero GVAE â‰ˆ GNN-det:

> "Los resultados de ablaciÃ³n (Tabla X) muestran que la estructura de grafo es 
> beneficiosa (X% de mejora), aunque el componente variacional no aporta mejoras 
> significativas en este contexto. Esto sugiere que la informaciÃ³n determinista 
> del grafo es suficiente para capturar las seÃ±ales relevantes."

## ğŸ”— ConexiÃ³n con HipÃ³tesis

Este experimento es el **Acto 1** de tu argumento cientÃ­fico:

**Acto 1 (AblaciÃ³n)**: Probar que estructura + incertidumbre funcionan
**Acto 2 (ComparaciÃ³n)**: Superar a SOTA con toda la potencia
**Acto 3 (AnÃ¡lisis)**: Entender QUÃ‰ capturan los modelos

Con `baseline.py` completas el Acto 1 de forma limpia y cientÃ­fica.
